__NUXT_JSONP__("/", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V,W,X,Y){return {data:[{}],fetch:[{openLog:{id:221927428,node_id:"MDEwOlJlcG9zaXRvcnkyMjE5Mjc0Mjg=",name:"opencv-log",full_name:"navarasu\u002Fopencv-log",private:a,owner:{login:o,id:p,node_id:q,avatar_url:r,gravatar_id:g,url:s,html_url:t,followers_url:u,following_url:v,gists_url:w,starred_url:x,subscriptions_url:y,organizations_url:z,repos_url:A,events_url:B,received_events_url:C,type:D,site_admin:a},html_url:E,description:"OpenCV based visual logger for debugging, logging and testing image processing code",fork:a,url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log",forks_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fforks",keys_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fkeys{\u002Fkey_id}",collaborators_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fcollaborators{\u002Fcollaborator}",teams_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fteams",hooks_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fhooks",issue_events_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fissues\u002Fevents{\u002Fnumber}",events_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fevents",assignees_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fassignees{\u002Fuser}",branches_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fbranches{\u002Fbranch}",tags_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Ftags",blobs_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fgit\u002Fblobs{\u002Fsha}",git_tags_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fgit\u002Ftags{\u002Fsha}",git_refs_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fgit\u002Frefs{\u002Fsha}",trees_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fgit\u002Ftrees{\u002Fsha}",statuses_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fstatuses\u002F{sha}",languages_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Flanguages",stargazers_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fstargazers",contributors_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fcontributors",subscribers_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fsubscribers",subscription_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fsubscription",commits_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fcommits{\u002Fsha}",git_commits_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fgit\u002Fcommits{\u002Fsha}",comments_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fcomments{\u002Fnumber}",issue_comment_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fissues\u002Fcomments{\u002Fnumber}",contents_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fcontents\u002F{+path}",compare_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fcompare\u002F{base}...{head}",merges_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fmerges",archive_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002F{archive_format}{\u002Fref}",downloads_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fdownloads",issues_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fissues{\u002Fnumber}",pulls_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fpulls{\u002Fnumber}",milestones_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fmilestones{\u002Fnumber}",notifications_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fnotifications{?since,all,participating}",labels_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Flabels{\u002Fname}",releases_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Freleases{\u002Fid}",deployments_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fopencv-log\u002Fdeployments",created_at:"2019-11-15T13:15:42Z",updated_at:"2020-11-03T10:21:57Z",pushed_at:"2020-08-22T19:39:47Z",git_url:"git:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fopencv-log.git",ssh_url:"git@github.com:navarasu\u002Fopencv-log.git",clone_url:"https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fopencv-log.git",svn_url:E,homepage:g,size:10664,stargazers_count:k,watchers_count:k,language:"Python",has_issues:c,has_projects:c,has_downloads:c,has_wiki:c,has_pages:c,forks_count:l,mirror_url:h,archived:a,disabled:a,open_issues_count:F,license:{key:G,name:H,spdx_id:I,url:J,node_id:K},forks:l,open_issues:F,watchers:k,default_branch:L,temp_clone_token:h,network_count:l,subscribers_count:4},serverless:{id:199639183,node_id:"MDEwOlJlcG9zaXRvcnkxOTk2MzkxODM=",name:"serverless-ruby-layer",full_name:"navarasu\u002Fserverless-ruby-layer",private:a,owner:{login:o,id:p,node_id:q,avatar_url:r,gravatar_id:g,url:s,html_url:t,followers_url:u,following_url:v,gists_url:w,starred_url:x,subscriptions_url:y,organizations_url:z,repos_url:A,events_url:B,received_events_url:C,type:D,site_admin:a},html_url:M,description:"A Serverless Plugin to deploy gems from Gemfile to AWS Layer",fork:a,url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer",forks_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fforks",keys_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fkeys{\u002Fkey_id}",collaborators_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fcollaborators{\u002Fcollaborator}",teams_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fteams",hooks_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fhooks",issue_events_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fissues\u002Fevents{\u002Fnumber}",events_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fevents",assignees_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fassignees{\u002Fuser}",branches_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fbranches{\u002Fbranch}",tags_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Ftags",blobs_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fgit\u002Fblobs{\u002Fsha}",git_tags_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fgit\u002Ftags{\u002Fsha}",git_refs_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fgit\u002Frefs{\u002Fsha}",trees_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fgit\u002Ftrees{\u002Fsha}",statuses_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fstatuses\u002F{sha}",languages_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Flanguages",stargazers_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fstargazers",contributors_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fcontributors",subscribers_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fsubscribers",subscription_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fsubscription",commits_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fcommits{\u002Fsha}",git_commits_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fgit\u002Fcommits{\u002Fsha}",comments_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fcomments{\u002Fnumber}",issue_comment_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fissues\u002Fcomments{\u002Fnumber}",contents_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fcontents\u002F{+path}",compare_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fcompare\u002F{base}...{head}",merges_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fmerges",archive_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002F{archive_format}{\u002Fref}",downloads_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fdownloads",issues_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fissues{\u002Fnumber}",pulls_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fpulls{\u002Fnumber}",milestones_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fmilestones{\u002Fnumber}",notifications_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fnotifications{?since,all,participating}",labels_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Flabels{\u002Fname}",releases_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Freleases{\u002Fid}",deployments_url:"https:\u002F\u002Fapi.github.com\u002Frepos\u002Fnavarasu\u002Fserverless-ruby-layer\u002Fdeployments",created_at:"2019-07-30T11:33:11Z",updated_at:"2020-10-20T08:36:58Z",pushed_at:"2020-08-18T13:52:07Z",git_url:"git:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fserverless-ruby-layer.git",ssh_url:"git@github.com:navarasu\u002Fserverless-ruby-layer.git",clone_url:"https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fserverless-ruby-layer.git",svn_url:M,homepage:g,size:575,stargazers_count:m,watchers_count:m,language:"JavaScript",has_issues:c,has_projects:a,has_downloads:c,has_wiki:a,has_pages:c,forks_count:i,mirror_url:h,archived:a,disabled:a,open_issues_count:N,license:{key:G,name:H,spdx_id:I,url:J,node_id:K},forks:i,open_issues:N,watchers:m,default_branch:L,temp_clone_token:h,network_count:i,subscribers_count:2}},{feeds:[{title:"Visually Debug, Log and Test an Image Processing Code Using OpenCV and Python",pubDate:"2019-12-06 13:59:29",link:"https:\u002F\u002Fblog.francium.tech\u002Fvisually-debug-log-and-test-an-image-processing-code-using-opencv-and-python-36e2d944ebf2?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002F36e2d944ebf2",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*OjiWAGDJXHYkIx0wGVmjRA.jpeg",description:O,content:O,enclosure:{},categories:["computer-vision",d,P,j,"logging"]},{title:"Using Multiple Elastic Search in Rails",pubDate:"2019-11-14 09:25:38",link:"https:\u002F\u002Fblog.francium.tech\u002Fusing-multiple-elastic-search-in-rails-c7263305731e?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002Fc7263305731e",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*akMVMnztqc0uPwYI1y9UFg.jpeg",description:Q,content:Q,enclosure:{},categories:["elasticsearch","ruby-on-rails","rails","ruby","search-engines"]},{title:"Get Started with Machine Learning in Visual Studio Code and Jupyter",pubDate:"2019-11-05 09:23:33",link:"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-in-visual-studio-code-and-jupyter-158d17cdc55e?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002F158d17cdc55e",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*q44ZZUV7w0_F0erjcCAJSQ.jpeg",description:R,content:R,enclosure:{},categories:[e,n,d,f,"visual-studio-code"]},{title:"Get Started with Machine Learning — Handy Python Tools",pubDate:"2019-10-21 10:08:39",link:"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-handy-python-tools-a1ce97085837?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002Fa1ce97085837",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*DNRGaFHQ6MXMUviSvgr_PQ.jpeg",description:S,content:S,enclosure:{},categories:[j,e,f,d,n]},{title:"Using Machine Learning for Color Calibration  with a color-checker",pubDate:"2019-10-21 10:05:54",link:"https:\u002F\u002Fblog.francium.tech\u002Fusing-machine-learning-for-color-calibration-with-a-color-checker-d9f0895eafdb?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002Fd9f0895eafdb",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*AoEteXXsuW_LT2w5GxoukQ.jpeg",description:T,content:T,enclosure:{},categories:[d,f,e,j,P]},{title:"Deploying Machine Learning Model to AWS Lambda with Serverless",pubDate:"2019-10-14 03:47:59",link:"https:\u002F\u002Fblog.francium.tech\u002Fdeploying-machine-learning-model-to-aws-lambda-with-serverless-a121a8253901?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002Fa121a8253901",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*8K7wEuGZdjXAIdvmp-BRlQ.jpeg",description:U,content:U,enclosure:{},categories:[V,"aws",d,"lambda",e]},{title:"Deploy Knative Service directly from source code using Kaniko \u002F Ko",pubDate:"2019-10-09 08:07:06",link:"https:\u002F\u002Fblog.francium.tech\u002Fdeploy-knative-service-directly-from-source-code-using-kaniko-ko-62f628a010d2?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002F62f628a010d2",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*33ac7ahdelqJXkridHTK_w.png",description:W,content:W,enclosure:{},categories:["kubernetes","knative","google-cloud","go",V]},{title:"Get Started with Machine Learning - Part 1",pubDate:"2019-10-05 20:41:07",link:"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-part-1-e24e980fa8a8?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002Fe24e980fa8a8",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*qWpuMFQc9rIZHd1skpDbxw.jpeg",description:X,content:X,enclosure:{},categories:[n,"linear-regression",f,d,e]},{title:"Prediction from Conditionally Dependent Data in Machine Learning",pubDate:"2019-08-13 04:48:44",link:"https:\u002F\u002Fblog.francium.tech\u002Fbuilding-prediction-model-from-conditionally-dependent-data-5bb0504864ea?source=rss-8df2e9eedd42------2",guid:"https:\u002F\u002Fmedium.com\u002Fp\u002F5bb0504864ea",author:b,thumbnail:"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*CWS1cEY1Lkz0pXErZIbWSA.png",description:Y,content:Y,enclosure:{},categories:["predictions",f,j,e,d]}],rows:9,perPage:6,currentPage:i}],mutations:[]}}(false,"Navarasu Muthu",true,"python","machine-learning","data-science","",null,1,"artificial-intelligence",32,7,26,"ai","navarasu",20145075,"MDQ6VXNlcjIwMTQ1MDc1","https:\u002F\u002Favatars1.githubusercontent.com\u002Fu\u002F20145075?v=4","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu","https:\u002F\u002Fgithub.com\u002Fnavarasu","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Ffollowers","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Ffollowing{\u002Fother_user}","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Fgists{\u002Fgist_id}","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Fstarred{\u002Fowner}{\u002Frepo}","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Fsubscriptions","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Forgs","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Frepos","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Fevents{\u002Fprivacy}","https:\u002F\u002Fapi.github.com\u002Fusers\u002Fnavarasu\u002Freceived_events","User","https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fopencv-log",5,"mit","MIT License","MIT","https:\u002F\u002Fapi.github.com\u002Flicenses\u002Fmit","MDc6TGljZW5zZTEz","master","https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fserverless-ruby-layer",3,"\n\u003Ch3\u003EVisually Debug, Log and Test an Image Processing Code using OpenCV and Python\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*OjiWAGDJXHYkIx0wGVmjRA.jpeg\"\u003E\u003Cfigcaption\u003EImage by \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002Fphotos\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1209823\"\u003EFree-Photos\u003C\u002Fa\u003E from \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1209823\"\u003EPixabay\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EAs a Programmer, we are well familiar with logging, debugging and testing our regular program.\u003C\u002Fp\u003E\n\u003Cp\u003Ei.e.,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cstrong\u003ELog\u003C\u002Fstrong\u003E the data value to record the behavior of the program and see it offline.\u003C\u002Fli\u003E\n\u003Cli\u003ELog them at various \u003Cstrong\u003Elog\u003C\u002Fstrong\u003E \u003Cstrong\u003Elevels\u003C\u002Fstrong\u003E to see the only preferred level of the log. E.g.\u003Cem\u003E,\u003C\u002Fem\u003E\u003Cem\u003EERROR, DEBUG, TRACE, INFO, WARN, etc.\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003EDebug\u003C\u002Fstrong\u003E the program locally and view the data value at a debug point. We drive through code by navigating to the next step or next debug point by pressing some short keys.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003ETest \u003C\u002Fstrong\u003Ethe code by comparing the expected data and report the failure as Pass or Fail. Record the failure data or error raised by the program for failure analysis.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EIn the fast-growing computer vision projects and its related programming, I see there is a need for similar kind requirements.\u003C\u002Fp\u003E\n\u003Cp\u003EWhile working in computer vision projects, I had lots of requirements to handle the logging, debugging and test reporting efficiently. Surprisingly I didn’t see any utility packages in python to satisfy the needs expect one package which is very preliminary and unmaintained.\u003C\u002Fp\u003E\n\u003Cp\u003ESo I had started implementing those requirements as utilities into projects and it makes my code clean, productive and maintainable. Later I have published a few of them as a python package called \u003Ca href=\"https:\u002F\u002Fpypi.org\u002Fproject\u002Fopencv-log\u002F\"\u003E\u003Cstrong\u003Eopencv-log\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fpypi.org\u002Fproject\u002Fopencv-log\u002F\"\u003Eopencv-log\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EThrough this blog, I like to discuss those requirements and its implementation for visually logging and testing using OpenCV and python.\u003C\u002Fp\u003E\n\u003Ch3\u003EImage Processing Data Aspect\u003C\u002Fh3\u003E\n\u003Cp\u003EIn the regular program, data are mostly human-readable to log, debug and compare.\u003C\u002Fp\u003E\n\u003Cp\u003EWhile here, we process a digital image represented as a number matrix. We apply various image processing techniques to transform the image or extract the required information. The data are mostly the number, binary or large matrices. Such data are not human-readable but it can be visualized for interpretation.\u003C\u002Fp\u003E\n\u003Ch4\u003EData Visualization\u003C\u002Fh4\u003E\n\u003Cp\u003EIn image processing, it is not just an image matrix to be visualized. We get a different type of data at the various stage as an output of image processing techniques.\u003C\u002Fp\u003E\n\u003Cblockquote\u003EFor e.g., We apply various techniques on the image like filtering, thresholding, feature extraction, feature matching, transformation, segmentation, edge and contours detection, hough lines detection, morphological operation, color analysis, and machine learning, etc.,\u003C\u002Fblockquote\u003E\n\u003Cp\u003EThe output of each technique has to be visualized differently, to analyze them. E.g.,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EFor thresholding, smoothing, edge detection, and morphological operation, the output is a matrix just that can be visualized as image. i.e. convert the matrix to the image. ( cv2.imwrite , cv2.imshow)\u003C\u002Fli\u003E\n\u003Cli\u003EFor contour, hough lines and feature detection, the output are coordinates and we draw the output on the input image. ( cv2.drawContours, cv2.drawKeypoints, cv2.drawMatches, cv2.line, cv2.rectangle)\u003C\u002Fli\u003E\n\u003Cli\u003EFor color analysis, we draw the color to visualize it.\u003C\u002Fli\u003E\n\u003Cli\u003EFor histogram and other data analysis, we plot them using matplotlib.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch3\u003EVisual Debugging \\ Logging\u003C\u002Fh3\u003E\n\u003Cp\u003EEvery computer vision developer is aware of all the above visualizations techniques. They are basics of image processing and is not any new idea to discuss in detail.\u003C\u002Fp\u003E\n\u003Cp\u003EIn general, at the analysis stage, we all play with this visualization in finding the right algorithms to analyze and extract or transform the image as per the business requirements. Once the code is matured for the implementation stage, we mostly wind up all the debugging lines and move only the actual image processing code for production.\u003C\u002Fp\u003E\n\u003Cp\u003EAgain when we find an issue in testing or production, we put these debugging lines back into code wherever required to find the issue. We will be adding visualization for major steps and then we will be moving to minor steps to corner the issue.\u003C\u002Fp\u003E\n\u003Ch4\u003ERequirements\u003C\u002Fh4\u003E\n\u003Cp\u003E\u003Cem\u003EMy requirements are quite simple, basic and most needed, they are,\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EFirst thing, I want the visual debugging lines to reside in my production code as a sleeper cell. Whenever needed, I will activate them.\u003C\u002Fli\u003E\n\u003Cli\u003EIt should have two ways of activations, it should act as a debugger or it should act as a logger.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003ELogger Mode\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EIn logger mode, it should behave like our regular logger. It should log the images in a readable format.\u003C\u002Fli\u003E\n\u003Cli\u003EThe data can be saved as an image file and load in HTML organized directly logging base64 image string to the HTML.\u003C\u002Fli\u003E\n\u003Cli\u003ELike logger, we can log based on levels at least three levels like ERROR, INFO and TRACE\u003C\u002Fli\u003E\n\u003Cli\u003ELog only in case of error or validation failure ( ERROR level)\u003C\u002Fli\u003E\n\u003Cli\u003ELog only major steps along with error steps (INFO level) or include the minor steps as well (TRACE level).\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EDebugger Mode\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EIn debugger mode, it should behave exactly behave like ide based debugger.\u003C\u002Fli\u003E\n\u003Cli\u003EIt should show the visualization as a popup window using something like cv2.imshow\u003C\u002Fli\u003E\n\u003Cli\u003EIf I press a short key, it should move to the next debug point and if the press ESC to should exit the program.\u003C\u002Fli\u003E\n\u003Cli\u003EWe can use the same logger level here, show the image for the data value only for error case or show me major steps alone or include minor steps as well.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003ELog utilities\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EApart from logging the matrix as an image, we can also add utils logging other data.\u003C\u002Fli\u003E\n\u003Cli\u003EE.g., if we need to see the hough lines, we take the previous output image or original image and we draw the line over it. The image used for drawing should be cloned. So that actual image not disturbed.\u003C\u002Fli\u003E\n\u003Cli\u003EThese steps can be made into util function like log_houghlines . Similarly, for all the possible outputs if we have util to log, it will save lots of time.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EYou can see these implementations of these features in the opencv-log package,\u003C\u002Fp\u003E\n\u003Cpre\u003Epip install opencv-log\u003C\u002Fpre\u003E\n\u003Cp\u003E\u003Cem\u003EAn Example from the \u003C\u002Fem\u003E\u003Cem\u003Eopencv-log package,\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cpre\u003Eimport cvlog as log\u003C\u002Fpre\u003E\n\u003Cpre\u003E# Set default mode and level\u003Cbr\u003E# If we dont set, then default mode is NONE\u003Cbr\u003E# and the default level is ERROR\u003C\u002Fpre\u003E\n\u003Cpre\u003Elog.\u003Cstrong\u003Eset_mode\u003C\u002Fstrong\u003E(log.\u003Cstrong\u003EMode\u003C\u002Fstrong\u003E.LOG)\u003Cbr\u003Elog.\u003Cstrong\u003Eset_level\u003C\u002Fstrong\u003E(log.\u003Cstrong\u003ELevel\u003C\u002Fstrong\u003E.TRACE)\u003C\u002Fpre\u003E\n\u003Cpre\u003Eimg = cv2.imread(\"sample.png\")\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cem\u003E# log or show the image or do nothing based on log mode and log level\u003C\u002Fem\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003Elog.\u003Cstrong\u003Eimage\u003C\u002Fstrong\u003E(log.\u003Cstrong\u003ELevel\u003C\u002Fstrong\u003E.INFO, img)\u003C\u002Fpre\u003E\n\u003Cpre\u003E# If mode is None, it remain as sleeper cell\u003Cbr\u003E# If mode is LOG, it logs image to html file.\u003Cbr\u003E# If mode is DEBUG, it shows image in pop window and wait for the key.\u003C\u002Fpre\u003E\n\u003Cp\u003EThis is a sample HTML log created using the logger mode,\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*xU71AXcvCfbdjT8CEaztJw.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EVisual Testing\u003C\u002Fh3\u003E\n\u003Cp\u003ETesting an image processing code requires human intelligence to confirm whether it is processed as expected. It cannot be automated completely. But it can be semi-automated with test reporting as a helper tool.\u003C\u002Fp\u003E\n\u003Cp\u003EDuring the implementation stage, we have a set of image types and we tune the code to match all the criteria for the different image types.\u003C\u002Fp\u003E\n\u003Cp\u003EThen to fine-tune and make production-ready, we test with a bunch of test images to find the failure cases. Ultimately, we need the report of failed images. Then after fine-tuning, we iterate the test. Also, we may need to cross-compare with the previous report.\u003C\u002Fp\u003E\n\u003Ch4\u003ERequirements\u003C\u002Fh4\u003E\n\u003Cp\u003E\u003Cem\u003EThe requirements can be simplified as below,\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EThe test should iterate with a list of images as file paths and process it using the processing script to be tested.\u003C\u002Fli\u003E\n\u003Cli\u003EIt should show me the processed image or results in a popup window one by one.\u003C\u002Fli\u003E\n\u003Cli\u003EManually, we confirm it as pass or fail by pressing any key. It generates a report with the result.\u003C\u002Fli\u003E\n\u003Cli\u003EIn case of failure, it records the output image and in case of any error, it records the error.\u003C\u002Fli\u003E\n\u003Cli\u003EThe report can be saved as a CSV or HTML file\u003C\u002Fli\u003E\n\u003Cli\u003EIn the case of HTML, we can combine the above logging features to make the report more informative to debug the actual issue.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Cem\u003EAn Example from the python package,\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cpre\u003Eimport cvtest as test\u003C\u002Fpre\u003E\n\u003Cpre\u003E# Process Image from image path\u003Cbr\u003Edef \u003Cstrong\u003Eprocess_image\u003C\u002Fstrong\u003E(imagepath):\u003Cbr\u003E    img = cv2.\u003Cstrong\u003Eimread\u003C\u002Fstrong\u003E(imagepath)\u003Cbr\u003E    # after processing...\u003Cbr\u003E\u003Cstrong\u003Ereturn\u003C\u002Fstrong\u003E img\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003Etest_image_paths\u003C\u002Fstrong\u003E=[\"example1.png\",\"example1.png\",\"error.png\"]\u003C\u002Fpre\u003E\n\u003Cpre\u003E# This shows image using cv2.imshow,\u003C\u002Fpre\u003E\n\u003Cpre\u003Etest.\u003Cstrong\u003Ereport\u003C\u002Fstrong\u003E(test_image_paths, process_image)\u003C\u002Fpre\u003E\n\u003Cpre\u003E# On presssing 'y' key, it report it as PASS\u003Cbr\u003E# On pressing any other key, it report it as FAIL and save output image for verification\u003Cbr\u003E# On any exception, it report it as ERROR with exception stack\u003C\u002Fpre\u003E\n\u003Cp\u003EYou find few of the implementation in the below repo,\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fopencv-log\"\u003Enavarasu\u002Fopencv-log\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"mailto:contact@francium.tech\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=36e2d944ebf2\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fvisually-debug-log-and-test-an-image-processing-code-using-opencv-and-python-36e2d944ebf2\"\u003EVisually Debug, Log and Test an Image Processing Code Using OpenCV and Python\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","opencv","\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*akMVMnztqc0uPwYI1y9UFg.jpeg\"\u003E\u003Cfigcaption\u003EImage by \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002Fusers\u002FPexels-2286921\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1868894\"\u003EPexels\u003C\u002Fa\u003E from \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1868894\"\u003EPixabay\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EFor the Multi Database support i.e. managing model-specific database connection, we were waiting for Rails 6. It enhances our application to scale on the database level. You can check the below blog for some more details.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Famazing-features-of-rails-6-0-ddb1a616b0af\"\u003EAmazing features of Rails 6.0\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003ESimilarly, we had a requirement to have multiple elastic search application for an architectural reason. That is we need to configure the elastic search specific to model. It is not a bigger deal like maintaining a database connection. In elastic search, it is just an API level integration.\u003C\u002Fp\u003E\n\u003Cp\u003EWith \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Felastic\u002Felasticsearch-rails\"\u003Eelasticsearch-rails\u003C\u002Fa\u003E gem, it can be simply configured by assigning the client directly to __elasticsearch__.client of the model.\u003C\u002Fp\u003E\n\u003Cp\u003EFor example, if you have a model Article,\u003C\u002Fp\u003E\n\u003Cpre\u003Eclass Article &lt; ActiveRecord::Base\u003Cbr\u003E  include Elasticsearch::Model\u003Cbr\u003Eend\u003C\u002Fpre\u003E\n\u003Cp\u003EThe elastic search client can be assigned directly to the model in the following way,\u003C\u002Fp\u003E\n\u003Cpre\u003EArticle.__elasticsearch__.client = Elasticsearch::Client.new url: “http:\u002F\u002F127.0.0.1:9200\"\u003C\u002Fpre\u003E\n\u003Cp\u003EIn our case, we have configured two elastic search clients, one specific to two models and another for remaining models.\u003C\u002Fp\u003E\n\u003Cp\u003EThe initializer configuration of the above is as,\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Cem\u003Einitializers\u002Felastic_search.rb\u003C\u002Fem\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E#Elastic Search for all Model Files\u003C\u002Fstrong\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003EElasticsearch::Model.client = Elasticsearch::Client.new url: \"http:\u002F\u002Fmain_elastic_host\u002F\", log: false\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E#Configure Separate elastic search for Specific Model Files\u003C\u002Fstrong\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003Esecondary_client = Elasticsearch::Client.new url: \"http:\u002F\u002Fsecond_elastic_host\", log: false\u003C\u002Fpre\u003E\n\u003Cpre\u003E[Model1, Model2].each do |model|\u003Cbr\u003E  model.__elasticsearch__.client = secondary_client\u003Cbr\u003Eend\u003C\u002Fpre\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"mailto:contact@francium.tech\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=c7263305731e\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fusing-multiple-elastic-search-in-rails-c7263305731e\"\u003EUsing Multiple Elastic Search in Rails\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*q44ZZUV7w0_F0erjcCAJSQ.jpeg\"\u003E\u003Cfigcaption\u003EPhoto by \u003Ca href=\"https:\u002F\u002Funsplash.com\u002F@nordwood?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\"\u003ENordWood Themes\u003C\u002Fa\u003E on \u003Ca href=\"https:\u002F\u002Funsplash.com\u002Fs\u002Fphotos\u002Foffice-desk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\"\u003EUnsplash\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EIn General, we will be often switching to the browser for executing the Jupyter notebook file (.ipynb) while we spent the most time with our favorite Visual Studio Code Editor for editing .py file.\u003C\u002Fp\u003E\n\u003Cp\u003ELike bringing in all languages to the single editor, VS Code solved this problem as well by integrating the jupyter notebook with it. Especially, the option to execute a .py file like a .ipynb file using comment syntax makes me avoid maintaining a separate .ipynb for debugging purposes.\u003C\u002Fp\u003E\n\u003Cp\u003EIn the previous article, we were setting up the environment using Anaconda and we have seen explored the jupyter notebook.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-handy-python-tools-a1ce97085837\"\u003EGet Started with Machine Learning — Handy Python Tools\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EIn this blog, We will see an alternative way of setting up the environment using the Visual Studio Code and explore the VS code Jupyter extension.\u003C\u002Fp\u003E\n\u003Ch3\u003ESetting up the Tools\u003C\u002Fh3\u003E\n\u003Cp\u003EThere lots of ways to install python. If we use \u003Cstrong\u003EPyEnv\u003C\u002Fstrong\u003E, we can easily manage multiple python versions like RVM for ruby.\u003C\u002Fp\u003E\n\u003Ch4\u003E\u003Cstrong\u003EInstall PyEnv\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cpre\u003Ecurl https:\u002F\u002Fpyenv.run | bash\u003C\u002Fpre\u003E\n\u003Cp\u003E\u003Cstrong\u003EImportant: \u003C\u002Fstrong\u003EYou need to add the .pyenv\\bin path to your .bashrc\\.zshrc . You will get the details at the end of the installation.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*TwgVSMapYS6snQzNJs1I6g.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EOnce added these three lines to .bashrc or .zshrc , restart the terminal.\u003C\u002Fp\u003E\n\u003Ch4\u003E\u003Cstrong\u003EInstall Python\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EInstall Python using pyenv and get it as a global python.\u003C\u002Fp\u003E\n\u003Cpre\u003Epyenv install 3.7.5\u003C\u002Fpre\u003E\n\u003Cpre\u003E# you can get the global python\u003C\u002Fpre\u003E\n\u003Cpre\u003Epyenv global 3.7.5\u003C\u002Fpre\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*hZn0XglG6y8Py3_Lge3nng.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EInstall Visual Studio Code and Python Extention\u003C\u002Fh4\u003E\n\u003Cp\u003EDownload and Install Visual Studio Code using the installer from \u003Ca href=\"https:\u002F\u002Fcode.visualstudio.com\u002F\"\u003Ehttps:\u002F\u002Fcode.visualstudio.com\u002F\u003C\u002Fa\u003E and install python extension.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*pjFfCEvfT1aO2KnzvYepsg.gif\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EInstall Jupyter\u003C\u002Fh4\u003E\n\u003Cp\u003EInstall jupyter using pip, pip install jupyter\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*_IGWikRZc6vSU_FEPerRWQ.gif\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EInstall ML Basic Libraries\u003C\u002Fh4\u003E\n\u003Cpre\u003Epip install scikit-learn\u003C\u002Fpre\u003E\n\u003Cpre\u003Epip install pandas\u003C\u002Fpre\u003E\n\u003Cpre\u003Epip install seaborn\u003C\u002Fpre\u003E\n\u003Cpre\u003Epip install tensorflow\u003C\u002Fpre\u003E\n\u003Cpre\u003Epip install Keras\u003C\u002Fpre\u003E\n\u003Cp\u003EHere scikit will install numpy &amp; scipy and seaborn will install matplotlib as dependencies.\u003C\u002Fp\u003E\n\u003Ch3\u003EUsing Jupyter Notebook in VS Code\u003C\u002Fh3\u003E\n\u003Cp\u003ECreate a new file with .ipynb extension\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*Th5uMWy6Z7-c6b9BbMXfvw.gif\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ESelect the python version where the jupyter and other ml libraries installed.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*tpkUHIkDw756-ZaVF-iyaQ.gif\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ELet's run-first code by typing the code and hitting SHITF + RETURN\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*VNEFbDc0wkMrNG5Ccr_P0g.gif\"\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EBeyond Jupyter\u003C\u002Fh3\u003E\n\u003Cp\u003EVisual studio code notebook extends the jupyter notebook really to the next level by bringing in the following benefits,\u003C\u002Fp\u003E\n\u003Ch4\u003E\u003Cstrong\u003ESingle Environment\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EFirst most thing, we get a single environment for managing notebook files along with python files. Else I need to take care of using the same python kernels for both.\u003C\u002Fp\u003E\n\u003Ch4\u003E\u003Cstrong\u003ECode Completion\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EIntelliSense support for code completion and parameter hints which we badly miss in the browser jupyter version.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*nfWKVtKdYKXcguKsbsBTLg.gif\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003E\u003Cstrong\u003EData viewer\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EData viewer provides an option to view our data like excel and we can sort and filter data for debugging. I love this feature as it saves much of my time. During data preprocessing, this helps to do manual cross verification.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*stEikM1KkfyKyBImQPyDEg.gif\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003E\u003Cstrong\u003ERunning Python file like Notebook\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EBy typing this comment text # %%before and after the piece of code, VS code treats the single piece of like notebook cell.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*s7DXCxx7DewAFFjmIIwMwQ.gif\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EAlso, we can use the comments section as a markdown notebook cell.\u003C\u002Fp\u003E\n\u003Cpre\u003E# %% [markdown]\u003Cbr\u003E# # This is example notebook title\u003C\u002Fpre\u003E\n\u003Cp\u003EFinally, We can export this python file to .ipynb . I have started using this comment into my production code and helps me in debugging like a charm.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"mailto:contact@francium.tech\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=158d17cdc55e\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-in-visual-studio-code-and-jupyter-158d17cdc55e\"\u003EGet Started with Machine Learning in Visual Studio Code and Jupyter\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","\n\u003Ch3\u003EGet Started with Machine Learning — Handy Python Tools\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*DNRGaFHQ6MXMUviSvgr_PQ.jpeg\"\u003E\u003Cfigcaption\u003EPhoto by \u003Ca href=\"https:\u002F\u002Fwww.pexels.com\u002F@seanpatrickphotography?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels\"\u003ESean Patrick \u003C\u002Fa\u003Efrom \u003Ca href=\"https:\u002F\u002Fwww.pexels.com\u002Fphoto\u002Fperson-with-tattoo-holds-python-2005922\u002F?utm_content=attributionCopyText&amp;utm_medium=referral&amp;utm_source=pexels\"\u003EPexels\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EAs part of the machine learning series, this article covers the necessary environmental setup to get hands dirty with machine learning in python.\u003C\u002Fp\u003E\n\u003Ch4\u003EWhy Python?\u003C\u002Fh4\u003E\n\u003Cp\u003EThere are many programming languages providing machine learning ecosystems like \u003Cem\u003ER, Python, Scala, Julia, and also Java.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EAmong them, Python is always the favorite choice mainly due to simplicity and extensive well-tested frameworks &amp; libraries. It has a great community of developers that we can understand from below \u003Ca href=\"https:\u002F\u002Finsights.stackoverflow.com\u002Fsurvey\u002F2019\u002F#technology\"\u003EStack Overflow’s Developer Survey 2019\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*MLvg6TD05hpUYUVH0YJ-pQ.png\"\u003E\u003Cfigcaption\u003E% of developers who are developing with the language or technology and have expressed interest in continuing to develop with it\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EBelow is the \u003Ca href=\"https:\u002F\u002Fwww.jetbrains.com\u002Fresearch\u002Fpython-developers-survey-2018\u002F\"\u003ESurvey of JetBrains 2018\u003C\u002Fa\u003E for python usage, we can see data analysis and machine learning leading the chart.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*v56fq8a18r0GE6Y9N9ZJ-Q.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E|Refer \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002Fe30fbcd9-f595-4a9f-803d-05ca5bf84612\"\u003Ehere\u003C\u002Fa\u003E for basic python data camp cheat sheet\u003C\u002Fp\u003E\n\u003Ch3\u003EAnaconda\u003C\u002Fh3\u003E\n\u003Cp\u003EAnaconda is a one-stop setup to get you started faster with machine learning. It brings all required tools and libraries for machine learning including python language gets installed to your system.\u003C\u002Fp\u003E\n\u003Ch4\u003ESetup Anaconda\u003C\u002Fh4\u003E\n\u003Cp\u003EYou download the GUI\\ CLI based installer from \u003Ca href=\"https:\u002F\u002Fwww.anaconda.com\u002Fdistribution\u002F\"\u003Ehere\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*EGiAbqR8VEJCJSRTY9UUrQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EIt installs python and dependent packages for machine learning.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*2jXX5ThRuIdgapJYelTLbg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EIt brings the following major tools,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EConda\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E — for dependency and environment management.\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EJupyter Notebook \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E— The best IDE for machine learning.\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EData Analysis\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E libraries — Numby, Pandas, Dask,etc.,\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EData Visualisation\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E libraries — Matplotlib, Seaborn, etc.,\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EMachine Learning and Deep Learning\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E libraries — Scikit learn, Tensorflow, Keras, etc.,\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003EAnd other 200 related libraries.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003ERun conda list to see the list of packages installed\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F994\u002F1*47ZooY6a1rZ-2xg6SbR5Wg.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EJupyter Notebook\u003C\u002Fh3\u003E\n\u003Cp\u003EWith Ananconda installation, we get this powerful IDE, \u003Cstrong\u003E\u003Cem\u003EJupyter Notebook\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E which saves lots of time when your working with machine learning.\u003C\u002Fp\u003E\n\u003Cp\u003EYou can start from the terminal by typing jupyter notebook\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*bXRBra04UpczgneRGRkhTg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EIt is a browser-based IDE that starts in the above port. By clicking New &gt; Python3, we can create our first notebook to get started.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*0deOq6NSrQBc11vQgGQv7w.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ELet’s run the first script by typing and press SHIFT + ENTER\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*XfYPRTxaI8rG_zm8TKAiRw.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EIt is almost like python console, you can notice the last line code is printed automatically and a new line created for running the next command.\u003C\u002Fp\u003E\n\u003Cp\u003EBeyond a python console, it can do lots like\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EWe can go back and re-run the previous command.\u003C\u002Fli\u003E\n\u003Cli\u003EIt displays machine learning data in tabular format.\u003C\u002Fli\u003E\n\u003Cli\u003EIt can display graphs and images inline below the command.\u003C\u002Fli\u003E\n\u003Cli\u003EEasy to add documentation and share as a single file to explain your concept &amp; code.\u003C\u002Fli\u003E\n\u003Cli\u003Eand a lot more.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EIt stores the notebook like as .ipynb and you can surf for lots of notebook files shared by other developers explaining the machine concepts &amp; code.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fs3.amazonaws.com\u002Fassets.datacamp.com\u002Fblog_assets\u002FJupyter_Notebook_Cheat_Sheet.pdf\"\u003Ehere\u003C\u002Fa\u003E for jupyter notebook data camp cheatsheet\u003C\u002Fblockquote\u003E\n\u003Ch3\u003EConda\u003C\u002Fh3\u003E\n\u003Cp\u003EConda is the package and environment manager bundled with Anaconda.\u003C\u002Fp\u003E\n\u003Cp\u003EWe can maintain multiple python environments and we can switch between them using conda . It is an alternative to virtualenv .\u003C\u002Fp\u003E\n\u003Cp\u003EThe command conda env list gives a list of environments.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1014\u002F1*p0eePC06Xu_Ukq4Nv5IZwg.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EInstall Conda Extention for Notebook\u003C\u002Fh4\u003E\n\u003Cp\u003ETo use the conda environment in jupyter, we need to install nb_conda\u003C\u002Fp\u003E\n\u003Cpre\u003Econda install nb_conda\u003C\u002Fpre\u003E\n\u003Cp\u003EThis adds a new tab to jupyter for managing conda.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*KBdeiHOgr0NFBSrdlDXFyw.png\"\u003E\u003C\u002Ffigure\u003E\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fconda\u002Fconda-docs\u002Ffiles\u002F1252315\u002Fconda-cheatsheet.pdf\"\u003Ehere\u003C\u002Fa\u003E for condas cheatsheet\u003C\u002Fblockquote\u003E\n\u003Ch3\u003EKnow Your ML Libraries\u003C\u002Fh3\u003E\n\u003Ch4\u003ENumpy and Pandas\u003C\u002Fh4\u003E\n\u003Cp\u003EIn machine learning, we deal with matrices of data which is basic of all libraries.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003ENumPy\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E is the most popular library in python for managing large n-dimensional arrays with matrix manipulation operations.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002Fe9f83f72-a81b-42c7-af44-4e35b48b20b7\"\u003Ehere\u003C\u002Fa\u003E for numpy data camp cheatsheet.\u003C\u002Fblockquote\u003E\n\u003Cp\u003E\u003Cstrong\u003EPandas\u003C\u002Fstrong\u003E provide high-level data manipulation tools \u003Cem\u003Ebuilt upon \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003ENumPy. \u003C\u002Fem\u003E\u003C\u002Fstrong\u003EPandas provide an in-memory table object like a spreadsheet with column names and row labels called Dataframe. You can also load data from CSV or Database. Additionally, it has the option to create pivot tables, computation, and plotting graphs.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"http:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002Fdbed353d-2757-4617-8206-8767ab379ab3\"\u003Ehere\u003C\u002Fa\u003E for basic panadas data camp cheatsheet and look \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002F9f0f2ae1-8bd8-4302-a67b-e17f3059d9e8\"\u003Ehere\u003C\u002Fa\u003E for advanced operations\u003C\u002Fblockquote\u003E\n\u003Ch4\u003EScipy and Scikit Learn\u003C\u002Fh4\u003E\n\u003Cp\u003E\u003Cstrong\u003ESciPy\u003C\u002Fstrong\u003E provides algorithms and functions core for scientific computation, like optimization, linear algebra, integration, interpolation, special functions, FFT, signal and image processing. It is\u003Cem\u003E built upon \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003ENumpy.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002F5710caa7-94d4-4248-be94-d23dea9e668f\"\u003Ehere\u003C\u002Fa\u003E for scipy data camp cheatsheet.\u003C\u002Fblockquote\u003E\n\u003Cp\u003E\u003Cstrong\u003EScikit-learn\u003C\u002Fstrong\u003E is \u003Cem\u003Ebuilt upon \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003ENumpy\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E and \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003ESciPy\u003C\u002Fem\u003E. \u003C\u002Fstrong\u003EIt is a collection of classical and advanced machine-learning algorithms and techniques.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002F5433fa18-9f43-44cc-b228-74672efcd116\"\u003Ehere\u003C\u002Fa\u003E for scikit data camp cheatsheet.\u003C\u002Fblockquote\u003E\n\u003Ch4\u003EMatplotlib and Seaborn\u003C\u002Fh4\u003E\n\u003Cp\u003E\u003Cstrong\u003EMatplotlib\u003C\u002Fstrong\u003E is a 2-dimensional plotting library like lots, histograms, power spectra, bar charts, error charts, scatterplots, etc., with just a few lines of code.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002F28b8210c-60cc-4f13-b0b4-5b4f2ad4790b\"\u003Ehere\u003C\u002Fa\u003E for matplotlib data camp cheatsheet.\u003C\u002Fblockquote\u003E\n\u003Cp\u003E\u003Cstrong\u003ESeaborn\u003C\u002Fstrong\u003E is a data visualization library\u003Cem\u003E based on \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Ematplotlib\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E. It provides a high-level interface for drawing attractive and informative statistical graphics.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002Ff9f06e72-519a-4722-9912-b5de742dbac4\"\u003Ehere\u003C\u002Fa\u003E for seaborn data camp cheatsheet.\u003C\u002Fblockquote\u003E\n\u003Ch4\u003ETensorFlow and Keras\u003C\u002Fh4\u003E\n\u003Cp\u003E\u003Cstrong\u003ETensorflow\u003C\u002Fstrong\u003E is a backend platform for machine learning for building and training deep neural networks. It provides APIs in most environments needed like Android, IoS, Mac OS, Windows, Linux, and Raspberry Pi.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003EKeras is\u003C\u002Fstrong\u003E a high-level API that is built on top of TensorFlow. we can build neural networks quickly with the Model and the Sequential API in Keras.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ERefer \u003Ca href=\"https:\u002F\u002Fdatacamp-community-prod.s3.amazonaws.com\u002F94fc681d-5422-40cb-a129-2218e9522f17\"\u003Ehere\u003C\u002Fa\u003E for keras data camp cheatsheet.\u003C\u002Fblockquote\u003E\n\u003Cp\u003EYou can follow below Machine learning Series, to get your hand dirty with a machine learning concept and examples\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-part-1-e24e980fa8a8\"\u003EGet Started with Machine Learning - Part 1\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"mailto:contact@francium.tech\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a1ce97085837\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-handy-python-tools-a1ce97085837\"\u003EGet Started with Machine Learning — Handy Python Tools\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","\n\u003Ch3\u003EUsing Machine Learning for Color Calibration with a Color Checker\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*AoEteXXsuW_LT2w5GxoukQ.jpeg\"\u003E\u003Cfigcaption\u003EImage by \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002Fusers\u002FYEYEQINQIN-3533307\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1744817\"\u003EYEYEQINQIN\u003C\u002Fa\u003E from \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1744817\"\u003EPixabay\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cstrong\u003EComputer Vision\u003C\u002Fstrong\u003E plays a vital role in Artificial Intelligence. In Francium Tech, we have delivered numerous solutions specifically in that field. Especially in \u003Cem\u003EDocument segmentation, Noise removal in the documents, Form Detection, Optical character recognition, Face Authentication and video Anti-spoofing,\u003C\u002Fem\u003E etc.,\u003C\u002Fp\u003E\n\u003Cblockquote\u003EThose solutions addressed major problems in the \u003Cem\u003Efinancial\u003C\u002Fem\u003E, health care, and insurance industry.\u003C\u002Fblockquote\u003E\n\u003Ch4\u003E\u003Cstrong\u003EColor Calibration\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003E\u003Cstrong\u003EColor Calibration\u003C\u002Fstrong\u003E is one of the segments that we addressed for a biological discipline. Apart from object detection and segmentation, it requires color correction for a color-based analysis.\u003C\u002Fp\u003E\n\u003Cp\u003EThe major problem in color analysis is that it is hard to control the lighting condition while taking the photo. The same color will be measured as a different color for photos taken under different lighting conditions.\u003C\u002Fp\u003E\n\u003Cblockquote\u003EColor calibration applied in many disciplines like space research, health care, food industry, and other color-managed workflow.\u003C\u002Fblockquote\u003E\n\u003Ch3\u003EProblem Statement\u003C\u002Fh3\u003E\n\u003Cp\u003EOur problem is somewhat similar to the color calibration used in the photography field using the color checker chart. The image has a set of known color regions like a color checker (not exactly) and we need to find the actual color of the unknown region which is used for clinical analysis.\u003C\u002Fp\u003E\n\u003Ch4\u003EExample Data\u003C\u002Fh4\u003E\n\u003Cp\u003EFor example, Let's take the \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FColorChecker\"\u003EColor Checker\u003C\u002Fa\u003E image example from its Wikipedia page.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cem\u003EBelow are images of \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003EMacbeth ColorChecker \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E(cardboard with 24 squares of painted samples) and photo with the color checker chart taken with certain lighting conditions\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*4HIui3BErUTtMb2TRXbBBw.png\"\u003E\u003C\u002Ffigure\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F538\u002F1*QoMeOyhAVSOndh7ueAAH0w.jpeg\"\u003E\u003Cfigcaption\u003E\u003Cstrong\u003E(A) \u003C\u002Fstrong\u003E\u003Cem\u003EMacbeth ColorChecker chart with sRGB number for the 24 squares. \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003E(B)\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E The image with the color checker chart taken under certain light condition\u003C\u002Fem\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EHere,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EThe \u003Cstrong\u003E\u003Cem\u003Eactual\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E colors of the 24 squares can be extracted from the \u003Cstrong\u003E\u003Cem\u003Eright\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E side image using OpenCV. We take it as input, X\u003C\u002Fli\u003E\n\u003Cli\u003EWe know the colors of these 24 squares from the \u003Cem\u003EMacbeth ColorChecker chart. \u003C\u002Fem\u003EWe take it as output, Y\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EUsing the extracted color of as input(X) and actual colors of the known color region as output(Y), we need to find the transformation relationship(function) between X and Y.\u003C\u002Fp\u003E\n\u003Cp\u003EUsing the transformation relationship, we can calibrate the color of the unknown regions in the image.\u003C\u002Fp\u003E\n\u003Ch4\u003EColors Representation\u003C\u002Fh4\u003E\n\u003Cp\u003EImages are digitally represented in n-dimensional space holding the color details. In Computer Vision, the images are read as 2 dimensional bit array holding the value of pixel value. Each pixel value can be represented in a different color model called color space like RGB, LAB, HSV.\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cstrong\u003EColor space \u003C\u002Fstrong\u003Eis a mathematical representation of color as tuples of numbers, typically as 3 or 4 values. For e.g., RGB is representation colors using \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FAdditive_primary_colors\"\u003Eadditive primary colors\u003C\u002Fa\u003E, Red, Blue and Greeen\u003C\u002Fblockquote\u003E\n\u003Ch4\u003EData Set\u003C\u002Fh4\u003E\n\u003Cp\u003EThe actual color of the 24 squares is,\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Cstrong\u003Ereference_colors\u003C\u002Fstrong\u003E = [[115,82,68],[194,150,130],[98,122,157][87,108,67],[133,128,177],[103,189,170],[214,126,44],[80,91,166],[193,90,99],[94,60,108],[157,188,64],[224,163,46],[56,61,150],[70,148,73],[175,54,60],[231,199,31],[187,86,149],[8,133,161],[243,243,242],[200,200,200],[160,160,160],[121,122,121],[85,85,85],[52,52,52]]\u003C\u002Fpre\u003E\n\u003Cp\u003EBelow is the color of the 24 squares extracted from the photo using open cv \u003Cem\u003E(by segmentation and finding the most dominant color)\u003C\u002Fem\u003E.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Cstrong\u003Eextracted_color\u003C\u002Fstrong\u003E = [[121,95,67],[209,178,148],[139,146,171],[108,130,65],[171,156,182],[182,208,183],[215,149,59],[96,88,178],[201,109,99],[82,51,101],[190,209,92],[219,181,65],[54,46,151],[123,177,90],[188,83,53],[226,211,74],[200,108,151],[105,152,184],[235,231,219],[219,214,197],[196,189,172],[153,147,131],[75,84,80],[32,33,37]]\u003C\u002Fpre\u003E\n\u003Cblockquote\u003EOne of the most important factors to consider when dealing with color calibration is having a valid source. If the color measuring source does not match the display’s capabilities, the calibration will be ineffective and give false readings.\u003C\u002Fblockquote\u003E\n\u003Ch3\u003EUsing Machine Learning\u003C\u002Fh3\u003E\n\u003Cp\u003EIf we look at the problem closely,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EWe can understand this a supervised machine learning problem as we have known the output Y.\u003C\u002Fli\u003E\n\u003Cli\u003EIt is a regression problem as the value to be predicted is continuous.\u003C\u002Fli\u003E\n\u003Cli\u003EHere the output is multidimensional. So, it is \u003Cstrong\u003Emultivariate \u003C\u002Fstrong\u003Eregression\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EIn machine learning, this case is solved using \u003Cem\u003Emultivariate algorithms\u003C\u002Fem\u003E like Partial Least Squares or by combining \u003Cem\u003Epolynomial algorithms\u003C\u002Fem\u003E or using a \u003Cem\u003Eneural network.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EAlso, it can be solved using a \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FSpline_(mathematics)\"\u003Espline\u003C\u002Fa\u003E-based technique like Thin plate spline as explained in \u003Ca href=\"https:\u002F\u002Fwww.ncbi.nlm.nih.gov\u002Fpubmed\u002F22969337\"\u003Ethis paper\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EUsing a neural network is an expensive idea for color calibration techniques as it takes more time to train. We will try a few other concepts in this blog.\u003C\u002Fp\u003E\n\u003Ch4\u003EUsing Partial Least Squares\u003C\u002Fh4\u003E\n\u003Cp\u003EIn simple word, PLS find the fundamental relations between two matrices (X and Y) by,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003Ereducing both X and Y dimension using PCA, and\u003C\u002Fli\u003E\n\u003Cli\u003Efinding the relation between the dimension reduced variable and label.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003ELets, try it with the scikit PLSRegression method for the data set.\u003C\u002Fp\u003E\n\u003Cp\u003ETrain with extracted_colors and reference_colors using PLS,\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*2RRQGDyZPgzyZIz_vRPOLw.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EThe R Square score shows that color fitting is not bad.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*OuspzB56vUHHSFTaw2R2cQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ELet's check this model by calibrating the entire picture,\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*8R0cShcQwB0D_3ziFkv-XA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*LSj02mmurNwPkkWeAPI33Q.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EFrom the color checkerboard, we can see the colors get transformed as per the reference colors.\u003C\u002Fp\u003E\n\u003Ch4\u003EUsing Polynomial Algorithms\u003C\u002Fh4\u003E\n\u003Cp\u003EThere are many techniques published on this. For e.g.\u003Cem\u003E Color Correction Using Root-Polynomial Regression by Graham D. Finlayson, Michal Mackiewicz, and Anya Hurlbert (Refer \u003C\u002Fem\u003E\u003Ca href=\"https:\u002F\u002Fieeexplore.ieee.org\u002Fdocument\u002F7047834\u002Fauthors\"\u003E\u003Cem\u003Ehere\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E)\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EUsing this technique, a color_correction matrix is derived as a coefficient from the input and output matrices. We can find its implementation in the \u003Ca href=\"https:\u002F\u002Fpypi.org\u002Fproject\u002Fcolour-science\u002F#colour-correction-colour-characterisation\"\u003Ecolor-science library\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*U5yGDzdYPsIktU7Q-rvlzg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EThere are also other color correction implementation found in the library for the following two techniques,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EUsing \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FVandermonde_matrix\"\u003EVandermonde_matrix\u003C\u002Fa\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003EA comparative study of the characterisation of colour cameras by means of neural networks and polynomial transforms \u003Cem\u003Eby Vien Cheung, Stephen Westland, David Connah, and Caterina Ripamonti(Refer \u003C\u002Fem\u003E\u003Ca href=\"https:\u002F\u002Fonlinelibrary.wiley.com\u002Fdoi\u002Fabs\u002F10.1111\u002Fj.1478-4408.2004.tb00201.x\"\u003E\u003Cem\u003Ehere\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E)\u003C\u002Fem\u003E.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch4\u003EUsing the Thin-Plate Spline Technique\u003C\u002Fh4\u003E\n\u003Cp\u003EApart from this technique, there is another article that uses the thin-plate spline technique to calibrate the color.\u003C\u002Fp\u003E\n\u003Cp\u003ERGB Color Calibration for Quantitative Image Analysis: The “3D Thin-Plate Spline” Warping Approach\u003Cem\u003E by Paolo Menesatti ,Claudio Angelini ,Federico Pallottino ,Francesca Antonucci ,Jacopo Aguzzi ,and Corrado Costa (Refer \u003C\u002Fem\u003E\u003Ca href=\"https:\u002F\u002Fwww.mdpi.com\u002F1424-8220\u002F12\u002F6\u002F7063\"\u003E\u003Cem\u003Ehere\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E)\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EThin plate Spline is an n-dimensional interpolation technique and it is the generalizations of single-dimensional cubic splines technique.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ECubic splines give an interpolating polynomial that is smoother and has smaller error than some other interpolating polynomial. Similarly, Thin-Plate Spline techique extented this technique n dimentional space by bending image as thin sheet of metal with multiple control points\u003C\u002Fblockquote\u003E\n\u003Cp\u003EThis technique is used to estimate the deformation between two images. This warping approach is used in a number of applications including medical image analysis, optical flow computation in anti-spoofing, character recognition of scribble writing in OCR, face and finger matching.\u003C\u002Fp\u003E\n\u003Cp\u003EThe same technique is used to warp the input color matrix with the reference matrix and the unknown color region is transformed using the warping.\u003C\u002Fp\u003E\n\u003Cp\u003EHere is the code that I have translated from the MATLAB code mentioned in the paper.\u003C\u002Fp\u003E\n\u003Ca href=\"https:\u002F\u002Fmedium.com\u002Fmedia\u002F0a0ecfd5411a19eda54e17d381e407be\u002Fhref\"\u003Ehttps:\u002F\u002Fmedium.com\u002Fmedia\u002F0a0ecfd5411a19eda54e17d381e407be\u002Fhref\u003C\u002Fa\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*TolLnLeGLDy5Y7en4rUIuQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cem\u003EOn comparative study, Finlayson’s Root-Polynomial Regression technique worked for our case giving correct color calibration results in most cases.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"mailto:contact@francium.tech\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d9f0895eafdb\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fusing-machine-learning-for-color-calibration-with-a-color-checker-d9f0895eafdb\"\u003EUsing Machine Learning for Color Calibration  with a color-checker\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","\n\u003Ch3\u003EDeploying Machine Learning Model to AWS Lambda using Serverless\u003C\u002Fh3\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*8K7wEuGZdjXAIdvmp-BRlQ.jpeg\"\u003E\u003Cfigcaption\u003EImage by \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002Fusers\u002Fsasint-3639875\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1822412\"\u003ESasin Tipchai\u003C\u002Fa\u003E from \u003Ca href=\"https:\u002F\u002Fpixabay.com\u002F?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1822412\"\u003EPixabay\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EDeploying the machine learning model to AWS lambda is a well-known step. That is.,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EDump the machine model object using \u003Ca href=\"https:\u002F\u002Fpypi.org\u002Fproject\u002Fjoblib\u002F\"\u003Ejoblib\u003C\u002Fa\u003E.\u003C\u002Fli\u003E\n\u003Cli\u003EUpload the model dump to s3 bucket, and\u003C\u002Fli\u003E\n\u003Cli\u003ELoad the s3 dump in AWS lambda and use it for prediction.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EIn this article, I am sharing one of our ML use cases and things considered in deploying it to AWS lambda.\u003C\u002Fp\u003E\n\u003Ch4\u003EUse case\u003C\u002Fh4\u003E\n\u003Cp\u003EThe use case is simple,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EOur Ruby on Rails(ROR) project needs to access the prediction model.\u003C\u002Fli\u003E\n\u003Cli\u003EIt needs the prediction for a single set of data.\u003C\u002Fli\u003E\n\u003Cli\u003EThe related ML use case is well discussed in this previous article,\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fbuilding-prediction-model-from-conditionally-dependent-data-5bb0504864ea\"\u003EPrediction from Conditionally Dependent Data in Machine Learning\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cul\u003E\u003Cli\u003EIn the preprocessing step, we need to make a \u003Cstrong\u003Eco-occurrence matrix \u003C\u002Fstrong\u003Eof the events. Also, we need to do one-hot encoding for categorical variables and scale the continuous variable.\u003C\u002Fli\u003E\u003C\u002Ful\u003E\n\u003Cp\u003ELet’s see things considered for deploying this use case.\u003C\u002Fp\u003E\n\u003Ch3\u003EThings Considered\u003C\u002Fh3\u003E\n\u003Cul\u003E\n\u003Cli\u003EAs we need to run the prediction model in rails, we go with cloud service either \u003Cstrong\u003E\u003Cem\u003Esagemaker\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E or \u003Cstrong\u003E\u003Cem\u003Elambda\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E for running the prediction function.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EAWS Lambda\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E is chosen instead of sagemaker as our model is a simple classical algorithm and prediction needs to be done for only single data at a time.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EAvoiding pandas\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E at the prediction layer to reduce package size as we are going to preprocess only single data.\u003C\u002Fli\u003E\n\u003Cli\u003EUse common projects to maintain the training and prediction layer. Also, share common code for preprocessing.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch4\u003EUse Serverless for deployment\u003C\u002Fh4\u003E\n\u003Cp\u003EFor AWS Lambda deployment, we considered using \u003Cstrong\u003Eserverless\u003C\u002Fstrong\u003E and its plugins for addressing the following set of requirements. I don't see any other tool matured enough.\u003C\u002Fp\u003E\n\u003Cp\u003EUse \u003Cstrong\u003Eserverless-dotenv-plugin\u003C\u002Fstrong\u003E to share common .env variable in lambda like \u003Cem\u003Es3 bucket name\u003C\u002Fem\u003E.\u003C\u002Fp\u003E\n\u003Cp\u003EUse \u003Cstrong\u003Eserverless-python-requirements \u003C\u002Fstrong\u003Eplugin,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003Eto use the same requirements.txt used in training and skip the unnecessary package for prediction.\u003C\u002Fli\u003E\n\u003Cli\u003EPack the package with native dependency using docker.\u003C\u002Fli\u003E\n\u003Cli\u003EReducing package size by removing the tests, information, and caches from the installed packages. For more details about this plugin, refer this blog\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fdeploying-python-packages-to-lambda-layers-using-serverless-plugin-c8fe1371e0b\"\u003ELambda Dependency Management using Serverless Plugin\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003EProject Setup\u003C\u002Fh3\u003E\n\u003Ch4\u003ETraining Layer\u003C\u002Fh4\u003E\n\u003Cp\u003EBased on the notebook of the previous article, I have created a training script to train and dump the model to the S3 bucket.\u003C\u002Fp\u003E\n\u003Ca href=\"https:\u002F\u002Fmedium.com\u002Fmedia\u002F5987571f6bccd07559569f5d096fcfed\u002Fhref\"\u003Ehttps:\u002F\u002Fmedium.com\u002Fmedia\u002F5987571f6bccd07559569f5d096fcfed\u002Fhref\u003C\u002Fa\u003E\u003Cp\u003EAlong with the trained model, required data and objects for preprocessing are also dumped.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*E_0inFUVxpBGd5HTQJgdSA.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EPrediction Layer\u003C\u002Fh4\u003E\n\u003Cp\u003EThe input data for prediction is passed in following JSON format,\u003C\u002Fp\u003E\n\u003Cpre\u003E{'custype': 'Type 1',\u003Cbr\u003E 'cus_point': 2517,\u003Cbr\u003E 'purchase_events': {'Product D': 'Brand 59', \u003Cbr\u003E                     'Product N': 'Brand 2' }}\u003C\u002Fpre\u003E\n\u003Cp\u003EThe lambda function gets the model dump from s3, preprocess it and predicts the value.\u003C\u002Fp\u003E\n\u003Cpre\u003Edef \u003Cstrong\u003Ehandler\u003C\u002Fstrong\u003E(\u003Cem\u003Eevent\u003C\u002Fem\u003E, \u003Cem\u003Econtext\u003C\u002Fem\u003E):\u003Cbr\u003E   dump=util.\u003Cstrong\u003EgetModel\u003C\u002Fstrong\u003E()\u003Cbr\u003E\u003Cbr\u003E\u003Cem\u003E# Preprocess\u003Cbr\u003E\u003C\u002Fem\u003Edata=\u003Cstrong\u003Epre_process\u003C\u002Fstrong\u003E(event,dump)\u003Cbr\u003E\u003Cbr\u003E\u003Cem\u003E    # Predict the value and its probability\u003Cbr\u003E\u003C\u002Fem\u003Evalue,probability=\u003Cstrong\u003Epredict\u003C\u002Fstrong\u003E(dump[\"model\"],data)\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E\u003Cem\u003Ereturn\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E json.dumps({\"value\": value, \"confidence\": probability})\u003C\u002Fpre\u003E\n\u003Cp\u003EOther data from a dump like \u003Cem\u003Eevent matrix, data scaler &amp; categories for one encoding\u003C\u002Fem\u003E are used to preprocess the input data.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*ea0EQC8EwfHzc_2twJgHMA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EI have created a simple encoder method to do one hot encoding instead of usingpandas.dummies . Other than that we don’t have any use case to include pandas in the prediction layer\u003C\u002Fp\u003E\n\u003Cpre\u003Edef one_hot_encoder(categories,data):\u003Cbr\u003E    oh_array=np.zeros(len(categories),dtype=int)\u003Cbr\u003E    try:\u003Cbr\u003E        oh_array[categories.index(data)]=1\u003Cbr\u003E    except:\u003Cbr\u003E        pass\u003Cbr\u003E    return oh_array\u003C\u002Fpre\u003E\n\u003Ch4\u003ECommon Util for both layer\u003C\u002Fh4\u003E\n\u003Cp\u003EMoved the common script of training and prediction to the util\u003Cem\u003E \u003C\u002Fem\u003Escript.\u003C\u002Fp\u003E\n\u003Ca href=\"https:\u002F\u002Fmedium.com\u002Fmedia\u002F734b7d24c309145d9d73293656a4cff4\u002Fhref\"\u003Ehttps:\u002F\u002Fmedium.com\u002Fmedia\u002F734b7d24c309145d9d73293656a4cff4\u002Fhref\u003C\u002Fa\u003E\u003Ch3\u003EServerless Configuration\u003C\u002Fh3\u003E\n\u003Ch4\u003EPlugin Configuration\u003C\u002Fh4\u003E\n\u003Cp\u003EBelow is the configuration for the dot_env and python requirement plugin.\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EUsing dotenv plugin to include environment variables to lambda\u003C\u002Fli\u003E\n\u003Cli\u003EdockerizePip: true install the packed in lambi docker.\u003C\u002Fli\u003E\n\u003Cli\u003Eslim:true remove unnecessary files and cache in the installed package.\u003C\u002Fli\u003E\n\u003Cli\u003EnoDeploy skip the listed packages from requirement.txt for lambda\u003C\u002Fli\u003E\n\u003Cli\u003Elayer upload the dependency package to the lambda layer.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*GefJ0B5vAfYILDHoSiw5ng.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EFunction Configuration\u003C\u002Fh4\u003E\n\u003Cp\u003EThe functions are configured to upload only lambda related function and skip other files related to training.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Cstrong\u003Efunctions\u003C\u002Fstrong\u003E:\u003Cbr\u003E  predict-brand:\u003Cbr\u003E    handler: src\u002Fmodel\u002Fpredict.handler\u003Cbr\u003E    layers:\u003Cbr\u003E      - {Ref: PythonRequirementsLambdaLayer}\u003Cbr\u003E    package:\u003Cbr\u003E      include: \u003Cbr\u003E        - src\u002Fmodel\u002Fpredict_vendor.py\u003Cbr\u003E        - src\u002Fmodel\u002Futil.py\u003C\u002Fpre\u003E\n\u003Cpre\u003E#Exclude the files in functions\u003Cbr\u003E\u003Cstrong\u003Epackage\u003C\u002Fstrong\u003E:\u003Cbr\u003E  individually: true\u003Cbr\u003E  exclude:\u003Cbr\u003E    - .\u002F**\u003C\u002Fpre\u003E\n\u003Ch4\u003ES3 bucket Role Permission\u003C\u002Fh4\u003E\n\u003Cp\u003EConfigure role permission for lambda to read s3 bucket\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*GOZ9NOA6dQN-NYsIRbu8vA.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EDeploying model and lambda function\u003C\u002Fh3\u003E\n\u003Cp\u003EThe complete code is here,\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fbrand_prediction\"\u003Enavarasu\u002Fbrand_prediction\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Ch4\u003ETrain and Upload model to s3\u003C\u002Fh4\u003E\n\u003Cpre\u003Ecd brand_prediction\u003Cbr\u003Evirtualenv venv\u003Cbr\u003Esource venv\u002Fbin\u002Factivate\u003Cbr\u003Epip install -r requirements.txt\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E# Train and upload model to s3 bucket\u003C\u002Fstrong\u003E\u003Cbr\u003Epython src\u002Fmodel\u002Ftrain.py\u003C\u002Fpre\u003E\n\u003Ch4\u003EDeploying Lambda function\u003C\u002Fh4\u003E\n\u003Cpre\u003Enpm install -g serverless\u003C\u002Fpre\u003E\n\u003Cpre\u003Enpm i -D serverless-dotenv-plugin\u003C\u002Fpre\u003E\n\u003Cpre\u003Esls plugin install -n serverless-python-requirements\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E# Deploy function to aws lambda\u003C\u002Fstrong\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003Esls deploy\u003C\u002Fpre\u003E\n\u003Ch4\u003EInvoke lambda function\u003C\u002Fh4\u003E\n\u003Cpre\u003Esls invoke -f predict-brand --data '{\"cus_type\": \"Type 1\",\\ \"cus_point\": 2517,\"purchase_events\": {\"Product D\": \"Brand 59\",\"Product N\": \"Brand 2\"}}'\u003C\u002Fpre\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*nF9qS5OVo4pb8uBrueuoAg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cblockquote\u003ERepeating the preprocessing steps in the prediction can be avoided using scikit pipeline. Also instead of dumping all related preprocessing data, it is enough dump the pipeline object alone.\u003C\u002Fblockquote\u003E\n\u003Cp\u003E\u003Cem\u003EIn the next article, we can see how to use scikit pipeline to simplify the prediction lambda script and also discuss other pipeline use cases.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"mailto:contact@francium.tech\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=a121a8253901\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fdeploying-machine-learning-model-to-aws-lambda-with-serverless-a121a8253901\"\u003EDeploying Machine Learning Model to AWS Lambda with Serverless\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","serverless","\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*33ac7ahdelqJXkridHTK_w.png\"\u003E\u003Cfigcaption\u003EPhoto by \u003Ca href=\"https:\u002F\u002Funsplash.com\u002F@yancymin?utm_source=medium&amp;utm_medium=referral\"\u003EYancy Min\u003C\u002Fa\u003E on \u003Ca href=\"https:\u002F\u002Funsplash.com\u002F?utm_source=medium&amp;utm_medium=referral\"\u003EUnsplash\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EThis is a follow up of the previous knative article where we got a brief intro into knative and learned how to deploy knative service. Before moving into this blog, look at the previous article for knative setup and to understand the context of this blog.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fbuild-your-own-serverless-platform-on-kubernetes-with-knative-87c82eb1b14d\"\u003EBuild Your Own Serverless Platform on Kubernetes with Knative\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EIn the hello world knative service deployment, we used local docker and docker registry for handling the image of our serverless service. It is the Kubernetes way of deployment. But when compared with a serverless way of deployment, these steps look inessential. i.e. managing a docker file, an image registry, docker daemon to build image and using a base image, etc.\u003C\u002Fp\u003E\n\u003Ch4\u003EDeploy from Source code\u003C\u002Fh4\u003E\n\u003Cp\u003EThese concerns can be addressed by deploying the source code directly from source code. This can be done in two ways.\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cstrong\u003EUsing Kaniko:\u003C\u002Fstrong\u003E We can build an image inside the Kubernetes cluster using the source code with docker file. So, we don’t need a local docker daemon to the build image.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003EUsing Ko:\u003C\u002Fstrong\u003E This is limited to go language. Ko uses the go import concept to fetch the binary our go app and pack it with \u003Ca href=\"https:\u002F\u002Fgithub.com\u002FGoogleContainerTools\u002Fdistroless\"\u003Edistroless\u003C\u002Fa\u003E image. So, we don’t need a docker file.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EBoth approaches need a docker registry to push and pull the image.\u003C\u002Fp\u003E\n\u003Ch3\u003EUsing Kaniko\u003C\u002Fh3\u003E\n\u003Ch4\u003EInstall and Configure Kaniko\u003C\u002Fh4\u003E\n\u003Cp\u003EInstall kaniko in the Kubernetes\u003C\u002Fp\u003E\n\u003Cpre\u003Ekubectl apply --filename \u003Ca href=\"https:\u002F\u002Fraw.githubusercontent.com\u002Fknative\u002Fbuild-templates\u002Fmaster\u002Fkaniko\u002Fkaniko.yaml\"\u003Ehttps:\u002F\u002Fraw.githubusercontent.com\u002Fknative\u002Fbuild-templates\u002Fmaster\u002Fkaniko\u002Fkaniko.yaml\u003C\u002Fa\u003E\u003C\u002Fpre\u003E\n\u003Ch4\u003EConfigure DockerHub Secrets for Kaniko\u003C\u002Fh4\u003E\n\u003Cp\u003EEncode your docker hub username and password\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F918\u002F1*1sN3SkE1jwBaDl63W_100Q.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EAdd this encoded string to the secrets with data key as username and password\u003C\u002Fp\u003E\n\u003Cpre\u003Eecho 'apiVersion\u003Cstrong\u003E:\u003C\u002Fstrong\u003E v1\u003Cbr\u003E   kind\u003Cstrong\u003E:\u003C\u002Fstrong\u003E Secret\u003Cbr\u003E   metadata\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E     name\u003Cstrong\u003E:\u003C\u002Fstrong\u003E basic-user-pass\u003Cbr\u003E     annotations\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E       build.knative.dev\u002Fdocker-\u003Cstrong\u003E0:\u003C\u002Fstrong\u003E https\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u002F\u002Findex.docker.io\u002Fv1\u002F\u003Cbr\u003E   type\u003Cstrong\u003E:\u003C\u002Fstrong\u003E kubernetes.io\u002Fbasic-auth\u003Cbr\u003E   data\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E     username\u003Cstrong\u003E:\u003C\u002Fstrong\u003E \u003Cstrong\u003EdXNlcm5hbWU=\u003C\u002Fstrong\u003E\u003Cbr\u003E     password\u003Cstrong\u003E:\u003C\u002Fstrong\u003E \u003Cstrong\u003EcGFzc3dvcmQ=\u003C\u002Fstrong\u003E' &gt; docker-secret.yaml\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E# Create a secret\u003C\u002Fstrong\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003Ekubectl apply --filename docker-secret.yaml secret \"basic-user-pass\" created\u003C\u002Fpre\u003E\n\u003Cp\u003EIt also needs a service account to access this secret\u003C\u002Fp\u003E\n\u003Cpre\u003Eecho '   apiVersion\u003Cstrong\u003E:\u003C\u002Fstrong\u003E v1\u003Cbr\u003E   kind\u003Cstrong\u003E:\u003C\u002Fstrong\u003E ServiceAccount\u003Cbr\u003E   metadata\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E     name\u003Cstrong\u003E:\u003C\u002Fstrong\u003E build-bot\u003Cbr\u003E   secrets\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E     - name\u003Cstrong\u003E:\u003C\u002Fstrong\u003E basic-user-pass' &gt;  service-account.yaml\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E# Create a service account\u003C\u002Fstrong\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003Ekubectl apply --filename service-account.yaml serviceaccount \"build-bot\" created\u003C\u002Fpre\u003E\n\u003Ch3\u003EBuild using Kaniko\u003C\u002Fh3\u003E\n\u003Cp\u003ELet’s use the same go web app example.\u003C\u002Fp\u003E\n\u003Cpre\u003Emkdir go_example\u003C\u002Fpre\u003E\n\u003Cpre\u003Ecd go_example\u003C\u002Fpre\u003E\n\u003Cpre\u003Eecho 'package main\u003Cbr\u003Eimport \"github.com\u002Fgin-gonic\u002Fgin\"\u003Cbr\u003Efunc ping(c *gin.Context) {\u003Cbr\u003E     c.JSON(200, gin.H{ \"message\": \"pong\",})\u003Cbr\u003E}\u003Cbr\u003Efunc main() {\u003Cbr\u003E        r := gin.Default()\u003Cbr\u003E        r.GET(\"\u002F\", ping)\u003Cbr\u003E        r.Run() \u002F\u002F listen and serve on 0.0.0.0:8080\u003Cbr\u003E}' &gt; helloworld.go\u003C\u002Fpre\u003E\n\u003Cp\u003EInit Go Modules for dependency management. Refer to \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fgo-modules-go-project-set-up-without-gopath-1ae601a4e868\"\u003Ethis blog\u003C\u002Fa\u003E for more detail.\u003C\u002Fp\u003E\n\u003Cpre\u003Ego mod init go_example\u003C\u002Fpre\u003E\n\u003Cp\u003ECreate a Dockerfile for the app\u003C\u002Fp\u003E\n\u003Cpre\u003Eecho 'FROM golang:alpine AS build-executableRUN mkdir \u002Fapp\u003Cbr\u003EADD . \u002Fapp\u003Cbr\u003EWORKDIR \u002FappRUN apk --no-cache add git\u003Cbr\u003ERUN go build\u003Cstrong\u003E\u003Cem\u003E# Using a Docker multi-stage build to create a lean image.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003EFROM alpine\u003Cbr\u003ERUN mkdir \u002Fapp\u003Cbr\u003ERUN apk --no-cache --update add ca-certificates\u003Cbr\u003ECOPY --from=build-executable \u002Fapp\u002Fgo_example \u002Fapp\u002Fgo_example\u003C\u002Fpre\u003E\n\u003Cpre\u003ECMD [\".\u002Fapp\u002Fgo_example\"]' &gt; Dockerfile\u003C\u002Fpre\u003E\n\u003Ch4\u003EPush the code\u003C\u002Fh4\u003E\n\u003Cpre\u003Egit init \u003Cbr\u003Egit add * \u003Cbr\u003Egit commit -m \"Created knative go example for kaniko\" \u003Cbr\u003Egit remote add origin https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fgoknative.git\u003Cbr\u003Egit push -u origin master\u003C\u002Fpre\u003E\n\u003Ch4\u003EDeploy directly from source code\u003C\u002Fh4\u003E\n\u003Cp\u003ELet's create service.yaml for deploying Knative service from source code.\u003C\u002Fp\u003E\n\u003Cpre\u003Eecho 'apiVersion\u003Cstrong\u003E:\u003C\u002Fstrong\u003E serving.knative.dev\u002Fv1alpha1\u003Cbr\u003E   kind\u003Cstrong\u003E:\u003C\u002Fstrong\u003E Service\u003Cbr\u003E   metadata\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E     name\u003Cstrong\u003E:\u003C\u002Fstrong\u003E app-from-source\u003Cbr\u003E     namespace\u003Cstrong\u003E:\u003C\u002Fstrong\u003E default\u003Cbr\u003E   spec\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E     runLatest\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E       configuration\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E         build\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E           apiVersion\u003Cstrong\u003E:\u003C\u002Fstrong\u003E build.knative.dev\u002Fv1alpha1\u003Cbr\u003E           kind\u003Cstrong\u003E:\u003C\u002Fstrong\u003E Build\u003Cbr\u003E           spec\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E             serviceAccountName\u003Cstrong\u003E:\u003C\u002Fstrong\u003E build-bot\u003Cbr\u003E             source\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E               git\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E                 url\u003Cstrong\u003E:\u003C\u002Fstrong\u003E \u003Cstrong\u003Ehttps:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fgoknative\u003C\u002Fstrong\u003E\u003Cstrong\u003E.git\u003C\u002Fstrong\u003E\u003Cbr\u003E                 revision\u003Cstrong\u003E:\u003C\u002Fstrong\u003E master\u003Cbr\u003E             template\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E               name\u003Cstrong\u003E:\u003C\u002Fstrong\u003E kaniko\u003Cbr\u003E               arguments\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E                 - name\u003Cstrong\u003E:\u003C\u002Fstrong\u003E IMAGE\u003Cbr\u003E                   value\u003Cstrong\u003E:\u003C\u002Fstrong\u003E \u003Cstrong\u003Edocker.io\u002Fnavarasu\u002Fapp-from-source:latest\u003C\u002Fstrong\u003E\u003Cbr\u003E             timeout\u003Cstrong\u003E:\u003C\u002Fstrong\u003E 10m\u003Cbr\u003E         revisionTemplate\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E           spec\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E             container\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E               image\u003Cstrong\u003E:\u003C\u002Fstrong\u003E \u003Cstrong\u003Edocker.io\u002Fnavarasu\u002Fapp-from-source:latest\u003C\u002Fstrong\u003E\u003Cbr\u003E               imagePullPolicy\u003Cstrong\u003E:\u003C\u002Fstrong\u003E Always' &gt; service.yaml\u003C\u002Fpre\u003E\n\u003Cp\u003EDeploy the knative service.\u003C\u002Fp\u003E\n\u003Cpre\u003Ekubectl apply --filename service.yaml\u003C\u002Fpre\u003E\n\u003Cp\u003EHere, the \u003Cstrong\u003Ebuild\u003C\u002Fstrong\u003E step creates an image using the docker file in source code and pushes it to the docker registry. Then as in the usual step, the pushed image is used to create knative service.\u003C\u002Fp\u003E\n\u003Ch4\u003EAccess the app\u003C\u002Fh4\u003E\n\u003Cpre\u003Ecurl -H \"Host: app-from-source.default.example.com\" \u003Ca href=\"http:\u002F\u002F35.203.155.229\u002F\"\u003Ehttp:\u002F\u002F35.203.155.229\u003C\u002Fa\u003E\u003C\u002Fpre\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*-n55HnNifutLcWpcTngvxA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EHere,\u003C\u002Fp\u003E\n\u003Cul\u003E\u003Cli\u003Ewe can find Host value for the function using the alias ksvc of knative service.\u003C\u002Fli\u003E\u003C\u002Ful\u003E\n\u003Cpre\u003Ekubectl get ksvc app-from-source\u003C\u002Fpre\u003E\n\u003Cul\u003E\u003Cli\u003Ewe can retrieve the IP Address of istio-ingressgateway\u003C\u002Fli\u003E\u003C\u002Ful\u003E\n\u003Cpre\u003E\u003Cem\u003Ekubectl get svc istio-ingressgateway --namespace istio-system\u003C\u002Fem\u003E\u003C\u002Fpre\u003E\n\u003Ch3\u003EUsing Ko\u003C\u002Fh3\u003E\n\u003Ch4\u003EInstall ko\u003C\u002Fh4\u003E\n\u003Cpre\u003EGO111MODULE=on go get github.com\u002Fgoogle\u002Fko\u002Fcmd\u002Fko\u003C\u002Fpre\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F934\u002F1*M9gL2YQJHMUlj9T_bY0Msg.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EConfigure docker registry path\u003C\u002Fh4\u003E\n\u003Cpre\u003Eexport KO_DOCKER_REPO=docker.io\u002Fnavarasu\u002Fapp-from-source\u003C\u002Fpre\u003E\n\u003Ch3\u003EBuild using Ko\u003C\u002Fh3\u003E\n\u003Cp\u003ELet’s use the same go example. But this time without any docker file.\u003C\u002Fp\u003E\n\u003Cpre\u003Emkdir go_example\u003C\u002Fpre\u003E\n\u003Cpre\u003Ecd go_example\u003C\u002Fpre\u003E\n\u003Cpre\u003Eecho 'package main\u003Cbr\u003Eimport \"github.com\u002Fgin-gonic\u002Fgin\"\u003Cbr\u003Efunc ping(c *gin.Context) {\u003Cbr\u003E     c.JSON(200, gin.H{ \"message\": \"pong\",})\u003Cbr\u003E}\u003Cbr\u003Efunc main() {\u003Cbr\u003E        r := gin.Default()\u003Cbr\u003E        r.GET(\"\u002F\", ping)\u003Cbr\u003E        r.Run() \u002F\u002F listen and serve on 0.0.0.0:8080\u003Cbr\u003E}' &gt; helloworld.go\u003C\u002Fpre\u003E\n\u003Cpre\u003E\u003Cstrong\u003E# Init go module\u003C\u002Fstrong\u003E\u003C\u002Fpre\u003E\n\u003Cpre\u003Ego mod init go_example\u003C\u002Fpre\u003E\n\u003Ch4\u003EPush the code\u003C\u002Fh4\u003E\n\u003Cpre\u003Egit init \u003Cbr\u003Egit add * \u003Cbr\u003Egit commit -m \"Created knative go example for ko\" \u003Cbr\u003Egit remote add origin https:\u002F\u002Fgithub.com\u002Fnavarasu\u002Fknativeko.git\u003Cbr\u003Egit push -u origin master\u003C\u002Fpre\u003E\n\u003Ch4\u003EDeploy from source code\u003C\u002Fh4\u003E\n\u003Cp\u003ELet's create service.yaml for deploying Knative service using go import path of the git repository instead of a docker image.\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\u003Cstrong\u003EFor e.g.,\u003C\u002Fstrong\u003E\u003C\u002Fblockquote\u003E\n\u003Cblockquote\u003EGo import for our git repo will be import(‘github.com\u002Fnavarasu\u002Fknativeko’)\u003C\u002Fblockquote\u003E\n\u003Cpre\u003Eecho 'apiVersion\u003Cstrong\u003E:\u003C\u002Fstrong\u003E serving.knative.dev\u002Fv1alpha1 \u003Cbr\u003Ekind\u003Cstrong\u003E:\u003C\u002Fstrong\u003E Service\u003Cbr\u003Emetadata\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E  name\u003Cstrong\u003E:\u003C\u002Fstrong\u003E ko-example\u003Cbr\u003E  namespace\u003Cstrong\u003E:\u003C\u002Fstrong\u003E default \u003Cbr\u003Espec\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E  runLatest\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E    configuration\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E      revisionTemplate\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E        spec\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E          container\u003Cstrong\u003E:\u003C\u002Fstrong\u003E\u003Cbr\u003E            image\u003Cstrong\u003E:\u003C\u002Fstrong\u003E github.com\u002Fnavarasu\u002Fknativeko' &gt; service.yaml\u003C\u002Fpre\u003E\n\u003Cp\u003ENow, deploy using ko\u003C\u002Fp\u003E\n\u003Cpre\u003Eko apply -f service.yaml\u003C\u002Fpre\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F?source=post_page---------------------------\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"http:\u002F\u002Fcontact@francium.tech\u002F?source=post_page---------------------------\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=62f628a010d2\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fdeploy-knative-service-directly-from-source-code-using-kaniko-ko-62f628a010d2\"\u003EDeploy Knative Service directly from source code using Kaniko \u002F Ko\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*qWpuMFQc9rIZHd1skpDbxw.jpeg\"\u003E\u003Cfigcaption\u003EPhoto by \u003Ca href=\"https:\u002F\u002Funsplash.com\u002F@agkdesign?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\"\u003EAlex Knight\u003C\u002Fa\u003E on \u003Ca href=\"https:\u002F\u002Funsplash.com\u002Fs\u002Fphotos\u002Frobot?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\"\u003EUnsplash\u003C\u002Fa\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cem\u003EBelow one is a conversation with my friend last week. He asked about how to get started with Data Science. When I shared him the \u003C\u002Fem\u003E\u003Ca href=\"https:\u002F\u002Fwww.youtube.com\u002Fplaylist?list=PLblh5JKOoLUICTaGLRoHQDuF_7q2GfuJF\"\u003E\u003Cstrong\u003E\u003Cem\u003EStatQuest\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E Machine learning video link\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, he asked me the difference between ML and Data Science?\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*ZlccOaYs83S5OZSecDVnRQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cem\u003EEvery beginner will come across these buzzwords \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003EMachine Learning\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E, \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003EArtificial Intelligence, \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003Eand \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003EData Science\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EArtificial Intelligence and Data Science are two dominant fields in today’s world redefining business to the next generation.\u003C\u002Fp\u003E\n\u003Cp\u003ELet’s get a brief overview of that before moving into Machine Learning\u003C\u002Fp\u003E\n\u003Ch3\u003EArtificial Intelligence and Data Science\u003C\u002Fh3\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EArtificial Intelligence\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E is wide term to discuss here. It aims to make the computer perform autonomous action by modeling human and animal capabilities.\u003C\u002Fp\u003E\n\u003Cp\u003EIn reality, it has a long way to go. The current AI is \u003Cem\u003E‘Narrow AI’ \u003C\u002Fem\u003Ewhich do not have full autonomy like a human but they are trained to perform certain task.\u003Cem\u003E For. e.g., a Self-driving car is trained to drive a car autonomously but it does not know it is driving a car.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EData Science\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E is an interdisciplinary field and it aims in processing any format of data and extracting useful information out of it.\u003C\u002Fp\u003E\n\u003Cp\u003EBoth AI and Data Science share techniques, tools and concepts among them to full fill their specific goal. We can’t isolate these techniques specific to certain fields.\u003C\u002Fp\u003E\n\u003Ch4\u003ETools and Techniques\u003C\u002Fh4\u003E\n\u003Cp\u003EThere are numerous techniques, tools, and concepts used by AI &amp; Data Science to fulfill their specific goals. Few of them are,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EMachine Learning\u003C\u002Fli\u003E\n\u003Cli\u003EImage Processing\u003C\u002Fli\u003E\n\u003Cli\u003ECloud Computing\u003C\u002Fli\u003E\n\u003Cli\u003EBig Data Techniques\u003C\u002Fli\u003E\n\u003Cli\u003EData Visualisation\u003C\u002Fli\u003E\n\u003Cli\u003Eand more …\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EAmong those techniques, Machine Learning is the most common concept used by both Data Science and AI. Let's move into the Machine learning concept.\u003C\u002Fp\u003E\n\u003Ch3\u003EMachine Learning\u003C\u002Fh3\u003E\n\u003Cp\u003EMachine Learning is a technique that analyzes the provided data using predefined algorithms and can make a prediction on new unanalyzed data.\u003C\u002Fp\u003E\n\u003Cblockquote\u003EFrom the definition of \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FArthur_Samuel\"\u003EArthur Samuel\u003C\u002Fa\u003E, a pioneer in the field of artificial intelligence who coined the word ‘Machine Learning’\u003C\u002Fblockquote\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*JmRDjDRo8CM8RDojqdNmsw.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EHow it differs from Traditional Programming?\u003C\u002Fh4\u003E\n\u003Cp\u003EIn usual programming, we program the logic manually to get the desired output.\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cstrong\u003E\u003Cem\u003ETraditional Programing: \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003EI\u003C\u002Fem\u003Enput + hardcoded logic\u002Frules = output\u003C\u002Fblockquote\u003E\n\u003Cp\u003EWhile in Machine Learning, we use algorithms to study logic\u002Fpattern behind the given input and output data. So that they don’t have to be programmed to get the desired output.\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cstrong\u003EMachine Learning : \u003C\u002Fstrong\u003EInput + output = derived logic \u002F rules using algorithm\u003C\u002Fblockquote\u003E\n\u003Cp\u003EThe core idea is to make a machine learn problem-solving itself with the help of machine learning algorithms.\u003C\u002Fp\u003E\n\u003Ch4\u003EMachine Learning Algorithms\u003C\u002Fh4\u003E\n\u003Cp\u003EAs of now, we have understood that machine learning solves a problem using predefined algorithms. Let us see what they are. Machine Learning can be categorized into two, Classical Learning and Deep Learning.\u003C\u002Fp\u003E\n\u003Cul\u003E\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EClassical Learning\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E are statistics-based methods and they are mostly interpretable. Some popular algorithms are Linear Regression, Logistic Regression, Decision Tree, Naive bayes, K nearest neighbour, K means, etc.,\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\u003C\u002Ful\u003E\n\u003Cblockquote\u003EApart from these algorithms,we have other two concepts like \u003Cstrong\u003EEnsemble\u003C\u002Fstrong\u003E and \u003Cstrong\u003EReinforcement \u003C\u002Fstrong\u003Ewhich helps to enhance classical algorithms.\u003C\u002Fblockquote\u003E\n\u003Cul\u003E\u003Cli\u003E\n\u003Cstrong\u003E\u003Cem\u003EDeep Learning\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E are modern methods performed using neural network and it can replace all above classical methods. Some popular architectures are Convolutional Neural Network (CNN), Recurrent Neural Networks (RNN), \u003C\u002Fem\u003EFeedforward Neural Network, \u003Cem\u003Eetc.,\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\u003C\u002Ful\u003E\n\u003Cblockquote\u003EEven Though Deep Learning has proved high performance in tasks like speech and image recognition, Classical algorithms still play better role than big neural network in many cases.\u003C\u002Fblockquote\u003E\n\u003Ch3\u003EGet started with Machine Learning\u003C\u002Fh3\u003E\n\u003Cp\u003ETo get started with Machine Learning, it is good to start with the classical algorithm. Classical algorithms are mostly categorized into supervised and unsupervised learning.\u003C\u002Fp\u003E\n\u003Ch4\u003ESupervised learning Vs Unsupervised Learning\u003C\u002Fh4\u003E\n\u003Cp\u003EIn \u003Cstrong\u003ESupervised Learning\u003C\u002Fstrong\u003E, we will have input, \u003Cstrong\u003EX\u003C\u002Fstrong\u003E and corresponding output, \u003Cstrong\u003EY\u003C\u002Fstrong\u003E. We will be finding the relationship between \u003Cstrong\u003EX\u003C\u002Fstrong\u003E and \u003Cstrong\u003EY\u003C\u002Fstrong\u003E.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EFor e.g.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E, Let say we have height and weight of 500 people. Identifying the weight of a person from a height is supervised learning. We can find the weight from the height by finding the relationship between height \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003EX\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E and weight \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003EY \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cstrong\u003EClassification\u003C\u002Fstrong\u003E and \u003Cstrong\u003ERegression\u003C\u002Fstrong\u003E concepts come under \u003Cem\u003Esupervised learning\u003C\u002Fem\u003E.\u003C\u002Fblockquote\u003E\n\u003Cp\u003EIn \u003Cstrong\u003Eunsupervised learning\u003C\u002Fstrong\u003E, we will have only an input variable \u003Cstrong\u003EX\u003C\u002Fstrong\u003E and we won’t have corresponding output variable \u003Cstrong\u003EY \u003C\u002Fstrong\u003E. We will be predicting based on the common details present in the input variables.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EFor e.g.,\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E Let's say we have runs and wickets of 500 cricket players and we don’t have information whether the player is a batsman or bowler. Identifying bowler and batsman among them is unsupervised learning.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cstrong\u003EAssociation\u003C\u002Fstrong\u003E and \u003Cstrong\u003EClustering\u003C\u002Fstrong\u003E concepts come under un\u003Cem\u003Esupervised learning\u003C\u002Fem\u003E\n\u003C\u002Fblockquote\u003E\n\u003Cp\u003EIn classical algorithms, Linear Regression is a simple concept and a good first algorithm to start with.\u003C\u002Fp\u003E\n\u003Cp\u003ELet's understand it with an example dataset and problem.\u003C\u002Fp\u003E\n\u003Ch4\u003EDataSet\u003C\u002Fh4\u003E\n\u003Cp\u003EI have taken the well known \u003Ca href=\"https:\u002F\u002Fwww.kaggle.com\u002Fmustafaali96\u002Fweight-height\"\u003Egender -height -weight kaggle dataset\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*jXQYkkbwHwot9TjJFaS-EA.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003E\u003Cstrong\u003EProblems\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Col\u003E\n\u003Cli\u003EFind the \u003Cstrong\u003Eweight\u003C\u002Fstrong\u003E based on height is well known \u003Cstrong\u003Eregression\u003C\u002Fstrong\u003E problem\u003C\u002Fli\u003E\n\u003Cli\u003EFind the \u003Cstrong\u003Egender-based\u003C\u002Fstrong\u003E on weight and height is a \u003Cstrong\u003Eclassification\u003C\u002Fstrong\u003E problem\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Ch3\u003ELinear Regression\u003C\u002Fh3\u003E\n\u003Cp\u003EBoth in regression and classification problem, we find the relationship between input \u003Cstrong\u003EX\u003C\u002Fstrong\u003E and output \u003Cstrong\u003EY \u003C\u002Fstrong\u003E. In Linear Regression, we use to predict a quantitative output value \u003Cstrong\u003EY\u003C\u002Fstrong\u003E from the input \u003Cstrong\u003EX \u003C\u002Fstrong\u003Eby finding the linear relationship between them\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\u003Cstrong\u003ETerms: Features and Labels\u003C\u002Fstrong\u003E\u003C\u002Fblockquote\u003E\n\u003Cblockquote\u003EIn Machine Learning, the input variable \u003Cstrong\u003EX \u003C\u002Fstrong\u003Eis referred as \u003Cstrong\u003Efeatures \u003C\u002Fstrong\u003Eand output variable \u003Cstrong\u003EY \u003C\u002Fstrong\u003Eis referred as \u003Cstrong\u003Elabels\u003C\u002Fstrong\u003E\n\u003C\u002Fblockquote\u003E\n\u003Cp\u003EFor e.g., If we plot a graph between X and Y values,\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003ELinear Regression finds the best line to fit the plotted data points\u003C\u002Fli\u003E\n\u003Cli\u003EUsing this best fit line, we can find the value of the corresponding Y value from the X geometrically.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch4\u003E\u003Cstrong\u003EFinding the best fit line\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cul\u003E\n\u003Cli\u003ETrying with different linear lines and predicting the new Y value from the X value using the drawn line.\u003C\u002Fli\u003E\n\u003Cli\u003EThen we find the difference between the predicted Y value with actual Y value. This is called the \u003Cstrong\u003Eerror \u003C\u002Fstrong\u003Ein the prediction.\u003C\u002Fli\u003E\n\u003Cli\u003EThe aim is to find the line which has the least error for all data points\u003C\u002Fli\u003E\n\u003Cli\u003EThere are different techniques to find this least error like \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FOrdinary_least_squares\"\u003E\u003Cstrong\u003E\u003Cem\u003EOrdinary Least Squares\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003Cstrong\u003E\u003Cem\u003E, \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FGradient_descent\"\u003E\u003Cstrong\u003E\u003Cem\u003EGradient Descent\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003Cstrong\u003E\u003Cem\u003E, \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FLasso_(statistics)\"\u003E\u003Cstrong\u003E\u003Cem\u003ELasso Regression\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003Cstrong\u003E\u003Cem\u003E, \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003Eand\u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003E \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FTikhonov_regularization\"\u003E\u003Cstrong\u003E\u003Cem\u003ERidge Regression\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003Cstrong\u003E\u003Cem\u003E.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\n\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Ch4\u003E\u003Cstrong\u003EMathematically\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cul\u003E\u003Cli\u003EThe equation of this line is represented as y = (\u003Cstrong\u003E\u003Cem\u003Em\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E * x) \u003C\u002Fem\u003E+ \u003Cstrong\u003E\u003Cem\u003Eb \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003Ewhere \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Em\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E and \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Eb\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E are coefficients.\u003C\u002Fem\u003E\n\u003C\u002Fli\u003E\u003C\u002Ful\u003E\n\u003Cblockquote\u003EHere, \u003Cstrong\u003Eb\u003C\u002Fstrong\u003E is the \u003Cstrong\u003Eintercept\u003C\u002Fstrong\u003E (point where line meets the y axis) and \u003Cstrong\u003Em\u003C\u002Fstrong\u003E is the \u003Cstrong\u003Eslope\u003C\u002Fstrong\u003E.\u003C\u002Fblockquote\u003E\n\u003Cul\u003E\n\u003Cli\u003EWe change these two coefficients to draw different lines to find the best fitting line among them.\u003C\u002Fli\u003E\n\u003Cli\u003EIn other words, the Linear regression model finds the best value of the two coefficient \u003Cstrong\u003Em\u003C\u002Fstrong\u003E and \u003Cstrong\u003Eb, \u003C\u002Fstrong\u003Ewhich results in a best-fit line for the given training data.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cblockquote\u003E\u003Cstrong\u003ETerms: Model and Training\u003C\u002Fstrong\u003E\u003C\u002Fblockquote\u003E\n\u003Cblockquote\u003EIn Machine Learning,the process of finding the best fit relationship function is referred as \u003Cstrong\u003ETraining \u003C\u002Fstrong\u003Eand relationship function derived is referred as \u003Cstrong\u003EModel\u003C\u002Fstrong\u003E . The data is used for train is referred as \u003Cstrong\u003ETraining Data\u003C\u002Fstrong\u003E\n\u003C\u002Fblockquote\u003E\n\u003Ch3\u003EPredicting Weight from Height using Linear Regression\u003C\u002Fh3\u003E\n\u003Cp\u003ERefer the article for environmental setup and tools to get started with machine learning,\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-handy-python-tools-a1ce97085837\"\u003Ehttps:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-handy-python-tools-a1ce97085837\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Ch4\u003EPrepare Data\u003C\u002Fh4\u003E\n\u003Cp\u003EPrepare input \u003Cstrong\u003EX\u003C\u002Fstrong\u003E and output \u003Cstrong\u003Ey\u003C\u002Fstrong\u003E from data,\u003C\u002Fp\u003E\n\u003Cpre\u003Eimport pandas as pd\u003Cbr\u003Edata = pd.read_csv(\"weight-height.csv\")\u003C\u002Fpre\u003E\n\u003Cpre\u003EX = data.drop([\"Height\",\"Gender\"],axis=1)\u003Cbr\u003Ey = data[\"Height\"]\u003C\u002Fpre\u003E\n\u003Cp\u003ESeparate the \u003Cstrong\u003Etest\u003C\u002Fstrong\u003E data and \u003Cstrong\u003Etrain\u003C\u002Fstrong\u003E data,\u003C\u002Fp\u003E\n\u003Cpre\u003Efrom sklearn.model_selection import train_test_split\u003Cbr\u003EX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.61,random_state=7)\u003C\u002Fpre\u003E\n\u003Cp\u003EFind the best model for the training data using scikit Linear Regression method(sklearn.linear_model.LinearRegression) . This method uses Ordinary Least Square to find the best fit line.\u003C\u002Fp\u003E\n\u003Cpre\u003Efrom sklearn.linear_model import LinearRegression\u003Cbr\u003Elr = LinearRegression()\u003Cbr\u003Elr.fit(X_train, y_train)\u003C\u002Fpre\u003E\n\u003Ch4\u003EVisualize the best fit model\u003C\u002Fh4\u003E\n\u003Cp\u003Elr object holds the best fit model. As we discussed earlier, it holds the value of the coefficients of the best fit line, \u003Cstrong\u003Em\u003C\u002Fstrong\u003E slope , and \u003Cstrong\u003Eb \u003C\u002Fstrong\u003Eintercept\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*7NJnoJv-9Bo-RKwj9iss8g.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EHere \u003Cstrong\u003EY \u003C\u002Fstrong\u003Eis weight and \u003Cstrong\u003Ex\u003C\u002Fstrong\u003E is the height. By substituting the weight in \u003Cstrong\u003Ex\u003C\u002Fstrong\u003E value in the above linear equation, we get the predicted height.\u003C\u002Fp\u003E\n\u003Cp\u003EThe plot of the data points and best-fit line of the training data is as below,\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*yLuclZSMHRHb462ErcpBmA.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EEvaluating a Regression algorithm\u003C\u002Fh3\u003E\n\u003Cp\u003EThe most important part of Machine Learning is evaluating the performance of the trained model,\u003Cstrong\u003E i.e,\u003C\u002Fstrong\u003E about evaluating the accuracy of the prediction.\u003C\u002Fp\u003E\n\u003Cp\u003EAs we are predicting a numerical value in the regression problem. We cannot verify by equalizing predicted value with actual. The predicted value will have minimal differences with actual value. This we call as an error.\u003C\u002Fp\u003E\n\u003Cp\u003EThis error value of all test data is evaluated with these three most common metrics, \u003Cstrong\u003EMean Absolute Error,\u003C\u002Fstrong\u003E \u003Cstrong\u003EMean Squared Error\u003C\u002Fstrong\u003E and \u003Cstrong\u003ERoot Mean Squared Error\u003C\u002Fstrong\u003E.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*6VBmFTgEHTvp9x6eXkndmA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ELower error value in all metrics shows better performance of the model.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cem\u003EIn the \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Enext blog\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E, we try the classification problem of the above data set, \u003C\u002Fem\u003E\u003Cstrong\u003Ei.e\u003C\u002Fstrong\u003E., predicting the gender from height and weight. \u003Cem\u003EAlso, list metrics to evaluate the classification model.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F?source=post_page---------------------------\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"http:\u002F\u002Fcontact@francium.tech\u002F?source=post_page---------------------------\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=e24e980fa8a8\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fget-started-with-machine-learning-part-1-e24e980fa8a8\"\u003EGet Started with Machine Learning - Part 1\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n","\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*CWS1cEY1Lkz0pXErZIbWSA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ERecently we have delivered prediction system for our client which has different data set with almost 95% categorical and 5% nominal features. The data set looks like a recommendation problem but we need to do a prediction out of it.\u003C\u002Fp\u003E\n\u003Cp\u003EThe problem some what looks like this, we need to predict which brand a customer would bought based on his purchase history and overall purchase trend. \u003Cem\u003EFor e.g., if a customer bought \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003ER\u003C\u002Fem\u003Eefrigerator\u003C\u002Fstrong\u003E\u003Cem\u003E and \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003EAC\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E from some brand, then we need to predict from which \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Ebrand\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E he would have bought \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Etelevision.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EThe problem is to predict only for one target product. for e.g., in above example, we need to predict the brand of the television.\u003C\u002Fp\u003E\n\u003Ch3\u003E\u003Cstrong\u003EDataSet\u003C\u002Fstrong\u003E\u003C\u002Fh3\u003E\n\u003Cp\u003EIn actual data, we have few more features like \u003Cstrong\u003Ecustomer type\u003C\u002Fstrong\u003E and \u003Cstrong\u003Ecustomer point \u003C\u002Fstrong\u003Eas well. I have prepared a dummy data set denoting the above problem. It is as follows,\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*5CfYO0SJgYTAvYGPfikOlg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EHere \u003Cstrong\u003Eproduct\u003C\u002Fstrong\u003E is denotes the type of product Television, AC.etc while \u003Cstrong\u003Ebrand\u003C\u002Fstrong\u003E denotes the brand of the product. Let’s assume that \u003Cstrong\u003Ecus_points\u003C\u002Fstrong\u003E is some numerical value denoting customer purchase capacity.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003ETo Predict: \u003C\u002Fstrong\u003EBrand of the \u003Cstrong\u003EProduct A\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Ch3\u003EData Analysis\u003C\u002Fh3\u003E\n\u003Cp\u003EOn a outward look, the problem looks like a recommendation problem. From the customer angle , we can visualize an \u003Cstrong\u003E\u003Cem\u003Ealso bought\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003Etrend. i.e., \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003EAlso bought from same brand trend.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Ch4\u003E\u003Cstrong\u003EAlso bought Trend\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EWe can analyse also bought trend of product D using item to item collaborative filtering. We can create co-occurrence matrix by encoding buying events to binary with \u003Cstrong\u003E1\u003C\u002Fstrong\u003E for product having \u003Cstrong\u003Esame\u003C\u002Fstrong\u003E \u003Cstrong\u003Ebrand\u003C\u002Fstrong\u003E as \u003Cstrong\u003EProduct A \u003C\u002Fstrong\u003Eand \u003Cstrong\u003E0\u003C\u002Fstrong\u003E for the else case.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*VgikqCdHNO0CdwBcusGJSg.png\"\u003E\u003Cfigcaption\u003ECo-occurrence Matrix\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EAs it is binary, jaccard_similarity_score will help us find the correlation among the products.\u003C\u002Fp\u003E\n\u003Cpre\u003E\u003Cem\u003Efrom\u003C\u002Fem\u003E sklearn.metrics \u003Cem\u003Eimport\u003C\u002Fem\u003E jaccard_similarity_score\u003C\u002Fpre\u003E\n\u003Cpre\u003Ecor = also_bought.corr(\u003Cem\u003Emethod\u003C\u002Fem\u003E=lambda \u003Cem\u003Ex\u003C\u002Fem\u003E, \u003Cem\u003Ey\u003C\u002Fem\u003E: jaccard_similarity_score(x, y))\u003C\u002Fpre\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*AMns4mEKaK0EeBEvTceM-w.png\"\u003E\u003C\u002Ffigure\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*OqKTpt-jL5fZkwiiFqwPRg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*wEvtHLLoUYbq9-E6nz-L3w.png\"\u003E\u003Cfigcaption\u003EProducts also bought with\u003Cstrong\u003E Product A\u003C\u002Fstrong\u003E\u003C\u002Ffigcaption\u003E\u003C\u002Ffigure\u003E\u003Cblockquote\u003EProduct N ,D and BD are having high correlation with Product A. They are bought from same brand on most of the cases than Product AP,AL and I.\u003C\u002Fblockquote\u003E\n\u003Cp\u003E\u003Cstrong\u003EFor e.g.\u003C\u002Fstrong\u003E,Whenever a customer has bought AC and Refrigerator from a brand, he also bought television from same brand. But not when he bought headset or book as they are not correlated or not sold in the brand.\u003C\u002Fp\u003E\n\u003Ch4\u003E\u003Cstrong\u003EConditional Dependence\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EIf we closely look at the above correlation result, we can notice a conditional dependence between the each buying event.\u003C\u002Fp\u003E\n\u003Cblockquote\u003EFrom \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FConditional_dependence\"\u003Ewiki\u003C\u002Fa\u003E, \u003Cstrong\u003Econditional dependence\u003C\u002Fstrong\u003E is a relationship between two or more events that are dependent when a third event occurs. \u003Cstrong\u003EFor e.g.\u003C\u002Fstrong\u003E, if \u003Cem\u003EA\u003C\u002Fem\u003E and \u003Cem\u003EB\u003C\u002Fem\u003E are two events that individually increase the probability of a third event \u003Cem\u003EC\u003C\u002Fem\u003E\n\u003C\u002Fblockquote\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*8o04S4gEGcHg2hTOQa52iA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*zu0Z4_FvLFnpLu4Ohd_PNQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003E\u003Cstrong\u003EAnalysing Customer Type\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EIf we plot the Customer type vs Brands of Product A, we can notice few brand were sold only to specific customer type. Based on this product example, it may look invalid. But for my actual data this type has influence factor for selecting the brand.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F911\u002F1*TIaPXh6gCvSuEPbR9bRkGg.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EAnalysing Customer Points\u003C\u002Fh4\u003E\n\u003Cp\u003ELet’s take mean of the customer points for each Brand of Product A to analyse its influence in selecting the brand.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*XnifywRSyX-PTzN-BdWeNw.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EBrand 10, 18 and 19 are purchased by customer having more purchase points. It may be due to high cost of the product.\u003C\u002Fp\u003E\n\u003Ch4\u003EAnalysing Prediction Label (Imbalanced Data Set)\u003C\u002Fh4\u003E\n\u003Cp\u003EBelow is the plot of brands count of Product A and we can see the labels are imbalanced.Brand 3 and Brand 8 have large data set than others.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*lgMC-8KFMkln3lXXF1RJhQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EMostly these kind of data set will balanced either by increasing the smaller samples or decreasing higher samples. But in our case the main influencing data is the conditional dependency. Changing the data will impact this purchase trend and can reduce the accuracy. Again the more purchase of a particular brand is also an information to be considered for prediction. So I don’t to do any re-sampling with this data.\u003C\u002Fp\u003E\n\u003Ch3\u003EChoosing a Prediction Model\u003C\u002Fh3\u003E\n\u003Cp\u003EIn above data analysis, we can understand that event of ‘buying related product from same brand’ has more influence in predicting the label. So, the brand of Product A can be predicted by measuring the \u003Cstrong\u003Econditional probability distribution \u003C\u002Fstrong\u003Eof all the buying events of the products.\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\n\u003Cstrong\u003EConditional probability\u003C\u002Fstrong\u003E is a measure of the \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FProbability\"\u003Eprobability\u003C\u002Fa\u003E of an \u003Ca href=\"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FEvent_(probability_theory)\"\u003Eevent\u003C\u002Fa\u003E occurring given that another event has occurred.\u003C\u002Fblockquote\u003E\n\u003Cp\u003EIn Supervised Machine Learning, \u003Cstrong\u003Econditional probability-based prediction \u003C\u002Fstrong\u003Ecan be done by \u003Cstrong\u003Ediscriminative classifiers \u003C\u002Fstrong\u003Elike Logistic Regression, SVM etc.\u003C\u002Fp\u003E\n\u003Cp\u003EEven the \u003Cstrong\u003EGenerative Classifiers\u003C\u002Fstrong\u003E like Naive Bayes can be used to predict the label. But generative classifiers like Naive Bayes well performs only with smaller dataset. When data grows, discriminative classifiers\u003Cstrong\u003E \u003C\u002Fstrong\u003Eperforms better as generative model reaches the asymptotic solution for fewer training sets than the discriminative model. This is well explained in the \u003Ca href=\"http:\u002F\u002Fai.stanford.edu\u002F~ang\u002Fpapers\u002Fnips01-discriminativegenerative.pdf\"\u003E\u003Cstrong\u003Eexperimental paper by Andrew Ng and Michael Jordan.\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Cblockquote\u003EDiscriminative model ‌measures the \u003Cstrong\u003Econditional probability distribution \u003C\u002Fstrong\u003E\u003Cstrong\u003Ep(y|x), \u003C\u002Fstrong\u003Ewhich can be used for predicting \u003Cstrong\u003Ey \u003C\u002Fstrong\u003E(label to be predicted)\u003Cstrong\u003E \u003C\u002Fstrong\u003Efrom \u003Cstrong\u003Ex \u003C\u002Fstrong\u003E(input data).\u003C\u002Fblockquote\u003E\n\u003Cblockquote\u003EGenerative model ‌measures the \u003Cstrong\u003Ejoint probability distribution \u003C\u002Fstrong\u003E\u003Cstrong\u003Ep(x,y) \u003C\u002Fstrong\u003Eand make the prediction \u003Cstrong\u003E\u003Cem\u003Ep(y|x)\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E using \u003Cstrong\u003EBayes Theorem.\u003C\u002Fstrong\u003E\n\u003C\u002Fblockquote\u003E\n\u003Cp\u003ELet’s start with most popular Discriminative classifier, Logistic Regression.Also we cross verify with Generative classifier like Naive Bayes and other Discriminative classifiers.\u003C\u002Fp\u003E\n\u003Ch3\u003EPreprocessing the data\u003C\u002Fh3\u003E\n\u003Cp\u003ELet’s group the data with cust_id and transpose the product to columns,\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*gphpaB9M8X7ZoxY46vjdYw.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003E\u003Cstrong\u003ECleaning Dirty Data\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EDropping all none values from prediction label (Product A)\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*8ejAlrImSdp8W6bBI0qwmw.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EAs Product data is most influencing features, we can drop rows which doesn’t have purchase history other than Product A. So, dropping rows with all Products columns having none value.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*WDfTaMtqJfLdAk8luV-FwQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003E\u003Cstrong\u003ESplit Training and Test Data\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EExtract the training label \u003Cstrong\u003Ey\u003C\u002Fstrong\u003E and input data \u003Cstrong\u003Ex\u003C\u002Fstrong\u003E from the grouped data and split the dataset for training and testing in 60:40 ratio.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*Qq2k2bCN1CCjV3TQVjuGOA.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003E\u003Cstrong\u003EEncoded Buying Events of Product\u003C\u002Fstrong\u003E\u003C\u002Fh4\u003E\n\u003Cp\u003EThe occurrence of an event not occurrence is encoded into binary. Let's generate the possible event combination for product and brand.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*ixdXbg7VHg5xT-nynSSl9w.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ETotally we have got 351 events. Using these combinations as columns, we can encode the buying event of each customer to form \u003Cstrong\u003Eco-occurrence matrix\u003C\u002Fstrong\u003E for the events\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*gqgytR31ik1WuiQ429BErA.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch4\u003EEncoded Categorical Data and Scaled Continuous Data\u003C\u002Fh4\u003E\n\u003Cp\u003EEncoded Customer Type value using One Hot Encoding and scaled the customer points using min-max scaling.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*hB1T_Hilx3JKlcLjY5hMpQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EBuilding the Prediction Model\u003C\u002Fh3\u003E\n\u003Cp\u003ETrained the model using \u003Cstrong\u003ELogistic Regression\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*bWX1Xr6xW868cseJLX7YqA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EPre-process the test data and evaluate the accuracy of the model\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*esutR0L_F1FPq61J_ki7Pg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EWe get \u003Cstrong\u003E82.8%\u003C\u002Fstrong\u003E accuracy with logistic regression\u003C\u002Fp\u003E\n\u003Ch4\u003ECompare With Naive Bayes\u003C\u002Fh4\u003E\n\u003Cp\u003EWhen we try the same data with Naive Bayes and we get \u003Cstrong\u003E78%\u003C\u002Fstrong\u003E accuracy\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*HzuYBOk9GYHa3I8RFfQISg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cblockquote\u003E\n\u003Cem\u003EFor\u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003E k fold cross validation, \u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003ELogistic Regression and Naive Bayes gets \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003E81.55%\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E and \u003C\u002Fem\u003E\u003Cstrong\u003E\u003Cem\u003E76.56%\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003Cem\u003E accuracy score . It shows the logistic regression perform well then Naive Bayes.\u003C\u002Fem\u003E\n\u003C\u002Fblockquote\u003E\n\u003Ch4\u003ECompare With Other Discriminative Classifiers\u003C\u002Fh4\u003E\n\u003Cp\u003EFirst we can try with one typical discriminative classifier, Support Vector Machine (SVM).\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EWith Support Vector Machine (Linear Kernel)\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*0jI6iUdj7PcFFxfZh1-qfA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EWith Support Vector Machine (Gaussian Kernel)\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*3stTzBI5zotqBm-uZ2STOQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003ESVM is almost performs same as Logistic Regression as the almost having same algorithm. Surprisingly, SVM using gaussian kernel slightly out performs than Logistic and SVM with linear kernel.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EWith K Nearest Neighbour (is it Discriminative Classifier?)\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EIt is some times debated that KNN is discriminative or generative . You can see a debate \u003Ca href=\"https:\u002F\u002Fstats.stackexchange.com\u002Fquestions\u002F105979\u002Fis-knn-a-discriminative-learning-algorithm\"\u003Ehere\u003C\u002Fa\u003E. Even though it comes under kind of discriminative category, it performed lower and almost same as Naive Bayes\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*A408yWTAdNfVcPvgebRelQ.png\"\u003E\u003C\u002Ffigure\u003E\u003Ch3\u003EEvaluating the Model\u003C\u002Fh3\u003E\n\u003Cp\u003EIn the above analysis, we notice most of them performing good based on classification accuracy. It is not enough parameter to validate which model is performing well.\u003C\u002Fp\u003E\n\u003Ch4\u003EK Fold cross-validation\u003C\u002Fh4\u003E\n\u003Cp\u003EFirst, we can evaluate the accuracy with K Fold cross-validation for the training set.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*eNpkFhwCE7vkq6JxxIFNcw.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EHere dots denote accuracy of each fold of training set. As our data is imbalanced, you can see the accuracy performs well for few data set and lower for some.\u003C\u002Fp\u003E\n\u003Cp\u003ESVM (Gaussian) and Linear Regression performs well than others like our existing accuracy result.\u003C\u002Fp\u003E\n\u003Cp\u003EHere the dots of SVM (Gaussian) are clustered between best and worst data set. It shows that SVM (Gaussian) is \u003Cstrong\u003E\u003Cem\u003Emarginally performing\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E better than LR. It may due to their loss function as Logistic loss diverges faster than hinge loss.\u003C\u002Fp\u003E\n\u003Cblockquote\u003ESVM minimizes hinge loss while logistic regression minimizes logistic loss.\u003C\u002Fblockquote\u003E\n\u003Ch4\u003EROC Curve and Precision Recall Curve\u003C\u002Fh4\u003E\n\u003Cp\u003EThe above accuracy is the ratio of number of correct predictions to the total number of input samples. It is doesn’t check \u003Cstrong\u003Eerrors\u003C\u002Fstrong\u003E of the prediction model like false positives and false negatives.\u003C\u002Fp\u003E\n\u003Cblockquote\u003EThere are 4 parameter for the interpretation,\u003C\u002Fblockquote\u003E\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cstrong\u003ETrue Positive: \u003C\u002Fstrong\u003EPredict an event when there was an event.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003ETrue Negative:\u003C\u002Fstrong\u003E Predict no event when in fact there was no event.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003EFalse Positive: \u003C\u002Fstrong\u003EPredict an event when there was no event.\u003C\u002Fli\u003E\n\u003Cli\u003E\n\u003Cstrong\u003EFalse Negative:\u003C\u002Fstrong\u003E Predict no event when in fact there was an event.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cp\u003EReceiver Operating Characteristic(\u003Cstrong\u003EROC\u003C\u002Fstrong\u003E) Curves and \u003Cstrong\u003EPrecision-Recall curves\u003C\u002Fstrong\u003E are supports to interpret the prediction of probabilities.\u003C\u002Fp\u003E\n\u003Cp\u003EROC curve plots between True Positive Rate (\u003Cstrong\u003ESensitivity) \u003C\u002Fstrong\u003Eand False Positive Rate (\u003Cstrong\u003E1 — Specificity) \u003C\u002Fstrong\u003Ewhile Precision-Recall curve plots between \u003Cstrong\u003EPrecision\u003C\u002Fstrong\u003E and \u003Cstrong\u003ERecall\u003C\u002Fstrong\u003E.\u003C\u002Fp\u003E\n\u003Cblockquote\u003E\u003Cem\u003EHere,\u003C\u002Fem\u003E\u003C\u002Fblockquote\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cem\u003ERecall\\True Positive Rate= True Positives \u002F (True Positives + False Negatives)\u003C\u002Fem\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cem\u003EPrecision = True Positives \u002F (True Positives + False Positives)\u003C\u002Fem\u003E\u003C\u002Fli\u003E\n\u003Cli\u003E\u003Cem\u003EFalse Positive Rate = False Positives \u002F (False Positives + True Negatives)\u003C\u002Fem\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*_wJ6bJCSqNYi3D88SDCXvg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*VQ7NgF9dbYAbvJXh5_rbvA.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EIn the above graph, the area under each curve (AUC) is used to summarize the skill of the model.\u003C\u002Fp\u003E\n\u003Cp\u003EAs our data are imbalanced, the precision recall curve plays a major role in defining the skill of the model. If we look at curves of both graph, Logistic Regression and SVM (Gaussian) have larger AUC (area under the curve) than others.\u003C\u002Fp\u003E\n\u003Cp\u003EAs the number of features (353) is relatively small than the number of training examples (4548), SVM (Gaussian) marginally well perform than Logistic Regression as discussed \u003Ca href=\"https:\u002F\u002Fstats.stackexchange.com\u002Fquestions\u002F95340\u002Fcomparing-svm-and-logistic-regression\"\u003Ehere\u003C\u002Fa\u003E.\u003C\u002Fp\u003E\n\u003Cblockquote\u003EBut if data grows, the SVM will perform lower than logistic regression.\u003C\u002Fblockquote\u003E\n\u003Cp\u003EAs the difference is almost minor between the two, we go with Logistic regression as it comparatively simpler and faster model.\u003C\u002Fp\u003E\n\u003Ch4\u003EConfusion Matrix and Its Report\u003C\u002Fh4\u003E\n\u003Cp\u003EIn the below matrix, diagonal cells represent true positives (expected value is correctly predicted) while other cells indicate the wrong prediction. The higher the diagonal values indicates the model is skillful.\u003C\u002Fp\u003E\n\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F1024\u002F1*naxRz0fZ_AUrYVNqDMHEHg.png\"\u003E\u003C\u002Ffigure\u003E\u003Cfigure\u003E\u003Cimg alt=\"\" src=\"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F996\u002F1*n5XOrcWt6NcENY2lhrWi1Q.png\"\u003E\u003C\u002Ffigure\u003E\u003Cp\u003EClassification Report provides \u003Cstrong\u003Eprecision, recall and f1 score\u003C\u002Fstrong\u003E of all the Brand classification and the average of all.\u003C\u002Fp\u003E\n\u003Cblockquote\u003EHere, \u003Cstrong\u003EPrecision \u003C\u002Fstrong\u003Emeasures of exactness of the prediction while \u003Cstrong\u003ERecall \u003C\u002Fstrong\u003Emeasure of completeness of the prediction. The \u003Cstrong\u003Ef1 score\u003C\u002Fstrong\u003E is the weighted average of precision and recall.\u003C\u002Fblockquote\u003E\n\u003Cp\u003EAll the three parameters with 0.8 above score looks encouraging.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003E\u003Cem\u003EThe same problem can be used to build a recommendation system using logistic regression. We can try it with a recommendation data set in next article.\u003C\u002Fem\u003E\u003C\u002Fstrong\u003E\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Ffrancium.tech\u002F?source=post_page---------------------------\"\u003E\u003Cem\u003EFrancium Tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E is a technology company laser focused on delivering top quality software of scale at extreme speeds. Numbers and Size of the data don’t scare us. If you have any requirements or want a free health check of your systems or architecture, feel free to shoot an email to \u003C\u002Fem\u003E\u003Ca href=\"http:\u002F\u002Fcontact@francium.tech\u002F?source=post_page---------------------------\"\u003E\u003Cem\u003Econtact@francium.tech\u003C\u002Fem\u003E\u003C\u002Fa\u003E\u003Cem\u003E, we will get in touch with you!\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Cimg src=\"https:\u002F\u002Fmedium.com\u002F_\u002Fstat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5bb0504864ea\" width=\"1\" height=\"1\" alt=\"\"\u003E\u003Chr\u003E\n\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002Fbuilding-prediction-model-from-conditionally-dependent-data-5bb0504864ea\"\u003EPrediction from Conditionally Dependent Data in Machine Learning\u003C\u002Fa\u003E was originally published in \u003Ca href=\"https:\u002F\u002Fblog.francium.tech\u002F\"\u003EFrancium Tech\u003C\u002Fa\u003E on Medium, where people are continuing the conversation by highlighting and responding to this story.\u003C\u002Fp\u003E\n")));